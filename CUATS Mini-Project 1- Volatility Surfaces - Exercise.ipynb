{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implied Volatility and Volatility Surfaces\n",
    "This CUATS mini-project focuses on computing the implied volatility of an option and plotting the volatility surface. We will also discuss how one can use volatility surfaces, or values derived from them, in trading strategies. This document also has both mathematical and coding exercises for you to complete as you read through the document (similar to the coding sessions ran during term). \n",
    "\n",
    "The CUATS mini-projects are intended to be a deeper dive into a topic, so this will be longer and more involved than a typical coding session. If you get stuck on the exercises (and can't progress even after looking at the hints) please go to the GitHub page for this project and ask for help. Also, where possible, the exercises are made such that you should be able to skip one and still make progress until near the end of the document where everything comes together, so it should be possible to skip to the next part if you're waiting for a response to your questions on GitHub.\n",
    "\n",
    "The general structure of the project is as follows:\n",
    "1. Imports and Libraries:\n",
    "    - Setting up a virtual environment for the project\n",
    "    - The Python libraries needed for the project\n",
    "1. What is the volatility surface?\n",
    "    - Black Scholes call prices, parameters involved\n",
    "    - Definition of the implied volatility, when does it exist?\n",
    "    - Volatility surfaces\n",
    "1. Getting options chains data\n",
    "    - How the yfinance library works, how to get options data from it\n",
    "    - Creating a function to collate the options chain information into a pandas dataframe\n",
    "1. Computing the implied volatility\n",
    "    - Analytical solution / estimate of the implied volatility in special cases\n",
    "    - The Bisection method\n",
    "    - The Newton-Raphson method, and extensions of it\n",
    "    - Brent's method\n",
    "1. Interpolating and plotting the volatility surface\n",
    "    - Importance of ensuring our volatility surfaces are arbitrage-free\n",
    "    - Discussion of parametric models for volatility surfaces\n",
    "    - Linear interpolation\n",
    "    - Cubic spline interpolation\n",
    "    - Plotting the volatility surface\n",
    "1. Volatility surface terms and properties\n",
    "    - Qualitative discussion of some features of the volatility surface (skew, smiles, term structure)\n",
    "    - Typical shapes for these in different markets\n",
    "1. Extensions\n",
    "    - Other modifications, improvements and improvements we can make to the project\n",
    "    - This section will also include some ideas for much more involved bonus extensions\n",
    "1. Example implementations\n",
    "    - Some ways one can use volatility surfaces directly in trading strategies.\n",
    "1. References\n",
    "1. Exercise hints\n",
    "    - Hints for each of the exercises, use these if you get stuck.\n",
    "\n",
    "In the session at 7pm on the 25th of August we will go through solutions to the exercises and we'll also discuss the example implementations of trading strategies that relate to the volatility surface. We would also encourage you to try out your own strategies building on the volatility surface code in this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Imports and Libraries:\n",
    "This project is intended to be done in Python. There are some Python libraries (and specific versions) one will need to complete it. Setting up a virtual environment for this project is recommended. For further information on setting up a virtual environment:\n",
    "\n",
    "- [Venv](https://docs.python.org/3/library/venv.html) - a Python module that helps with creating python virtual environments.\n",
    "- [Managing environments in conda](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)\n",
    "\n",
    "For a more detailed explanation of the benefits of virtual environments, see this page - [Python Virtual Environments: A Primer](https://realpython.com/python-virtual-environments-a-primer/). On the GitHub, we've attached some more explicit instructions for setting up a Python virtual environment using Anaconda. For those who are already familiar with virtual environments, the packages needed for the project are:\n",
    "- Python(3.12.4) - https://www.python.org/downloads/release/python-3124/, we need version 3.12.4 to be compatible with yfinance version 0.2.40. \n",
    "\n",
    "- NumPy(1.26.4) - https://numpy.org/, a library that provides fast and easy to use arrays. (Install instructions: https://numpy.org/install/)\n",
    "\n",
    "- SciPy(1.14.0) - https://scipy.org/, a library that provides many useful algorithms and functions. We're mainly using it for some probability/statistics functions. (Install instructions: https://scipy.org/install/)\n",
    "\n",
    "- yfinance(0.2.40) - https://pypi.org/project/yfinance/, a library that provides easy access to yahoo finance, a great source of free market data (Install instructions: on the pypi page linked. Note: In the future, these may need to be updated further as old versions of yfinance sometimes stop working. If you are unable to find options data, check yfinance version 0.2.40 is the most current version, and if not update to the current one. To update in conda, one may need to use the following: conda install -c conda-forge yfinance=0.2.40=pyhd8ed1ab_0).\n",
    "\n",
    "- Pandas(2.2.2) - https://pandas.pydata.org/, a library that provides fast DataFrame objects which we'll use for storing data. Plotly and yfinance both use Pandas so using it makes it easier to interface with them. (Install instructions: https://pandas.pydata.org/getting_started.html)\n",
    "\n",
    "- Plotly(5.22.0) - https://plotly.com/python/, a library that makes producing high quality plots easy. We'll use this for making visualisations of volatility surfaces. (Install instructions: https://plotly.com/python/getting-started/)\n",
    "\n",
    "- Matplotlib(3.9.1) - https://matplotlib.org/, the standard python plotting library. Only used for a single plot which can't be easily replicated in plotly, so this is optional. (Install instructions: https://matplotlib.org/stable/install/index.html)\n",
    "\n",
    "- nbformat(5.10.4) - https://pypi.org/project/nbformat/, the base Jupyter notebook format, sometimes the Plotly plots won't show unless this package is installed.\n",
    "\n",
    "- ipykernel(6.29.5) - https://pypi.org/project/ipykernel/, a package that is needed to run Jupyter Notebooks. For a brief introduction to Jupyter Notebooks, see: https://jupyter.org/try-jupyter/notebooks/?path=notebooks/Intro.ipynb\n",
    "\n",
    "Standard Python packages we'll use:\n",
    "\n",
    "- datetime (3.12.4) - https://docs.python.org/3/library/datetime.html, a standard python library that includes useful tools for storing and modifying dates. \n",
    "\n",
    "- os (optional) - We'll also use the standard Python os library that allows one to save and load files from the directory. This is an optional extra, and isn't necessary for the project. If you're running this notebook on a different platform (for instance Google Colab) you'll need to rewrite the code to match how files are read and written to on that platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - What is the volatility surface?\n",
    "\n",
    "## 2.1 - The Black-Scholes model\n",
    "A common method to price options is the Black-Scholes model (though there are others, some of which are discussed in the extension). If we consider an option created at time $t = 0$ it will have the following (widely known) parameters:\n",
    "- T - the time at which the option expires.\n",
    "- K - the strike price of the option.\n",
    "- $S_0$ - the price of the stock at time $t=0$.\n",
    "- r - the risk-free interest rate available.\n",
    "Then if we want to know the fair price of an option in the Black-Scholes model at time $t$ the following parameters are relevant:\n",
    "- t - the current time.\n",
    "- $\\sigma$ - the standard deviation of the stocks returns, also known as the volatility.\n",
    "- $\\mu$ - the drift rate (average rate at which we expect stock prices to increase).\n",
    "\n",
    "The Black-Scholes price of a call option at time $t$ with strike $K$, underlying price $S_t$ at time $t$ and expiration time $T$ is given by:\n",
    "\n",
    "$C(S_t,t) = S_t \\times \\Phi(d_1) - K \\times \\Phi(d_2) e^{-r(T-t)}$\n",
    "\n",
    "Where $\\Phi$ is the cumulative distribution function of a standard normal random variable and:\n",
    "\n",
    "$$ d_1 = \\frac{1}{\\sigma \\sqrt{T-t}} \\left\\{ ln\\left(\\frac{S_t}{K}\\right) + \\left(r + \\frac{\\sigma^2}{2}\\right)(T-t)\\right\\}$$\n",
    "\n",
    "$$ d_2 =  \\frac{1}{\\sigma \\sqrt{T-t}} \\left\\{ ln\\left(\\frac{S_t}{K}\\right) + \\left(r - \\frac{\\sigma^2}{2}\\right)(T-t)\\right\\}$$\n",
    "\n",
    "Alternatively, one can write $d_2 = d_1 - \\sigma \\sqrt{T-t} $. \n",
    "\n",
    "For a put option, one can show using put-call parity that the price is:\n",
    "\n",
    "$$ P(S_t, t) = K \\times \\Phi(-d_2)e^{-r(T-t)} - S_t \\times \\Phi(-d_1)$$\n",
    "\n",
    "The last of our parameters, $\\mu$, does not appear in either of the pricing formula. This is because we value options under something called the risk neutral measure. The full explanation of this is quite mathematical, and beyond the scope of this project. A (quite simplified) explanation for why the drift $\\mu$ does not feature in the Black-Scholes price is as follows:\n",
    "- Consider a call option with strike $K=0$. At the expiry time T, this would payout the exact price of the stock at time T, i.e. S_T.\n",
    "- Therefore, the option pays out exactly the same value as:\n",
    "    - Buying the stock right now, costing S_t\n",
    "    - Selling it at time T, paying out S_T\n",
    "- Therefore, the option should cost exactly the same value as the stocks current value S_t (and there is no drift).\n",
    "- More generally, if there was some known drift that everyone agreed on, then it should already be priced into the current value of the stock and so doesn't need to be included in the pricing formula. \n",
    "\n",
    "One may debate whether these assumptions are reasonable. Interest rates are not fixed over time, and there's also strong evidence that volatility is not constant over time. These are simply the assumptions of the Black-Scholes model.\n",
    "\n",
    "We can now determine the theoretical Black-Scholes price of any option. As the current time $t$, risk-free rate $r$, current price $S_t$, strike price $K$ and expiration date/time $T$ are all known, and as $\\mu$ doesn't affect the Black-Scholes price, we can compute the price provided we know the volatility $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Volatility\n",
    "From the previous section, if we know the volatility we can compute the (Black-Scholes) price of any given option using the above formulae. The volatility that's important for pricing is the volatility of the underlying asset over the time $[t,T]$. As the current time is $t$, this interval is in the future (so we don't know what it is yet). To remedy this, one can use a range of methods to estimate the future volatility. The simplest way is to use the historical volatility (the standard deviation of the log returns, for further details see [here](https://www.macroption.com/historical-volatility-calculation/)) over some time period.\n",
    "\n",
    "This method may perform well in some cases, but consider the following:\n",
    "- Say the underlying asset is stock of company A. \n",
    "- Company A is a pharmaceutical company that produces drugs, and over the past year they've been working on a promising new drug which would revolutionise the treatment of some widespread disease (and lead to massive profits for the company).\n",
    "- This drug has a clinical trial in the next three months.\n",
    "\n",
    "Clearly if the drug trial is successful, company A is more likely to be profitable in the future and so its share price will increase. On the other hand if it is unsuccessful, company A's share price will likely decrease. In either case, we would expect to see a large change in share prices (and so we should price with a higher volatility than the historic volatility would suggest) for an option expiring in a bit over 3 months. Therefore, in this case the realised volatility (the volatility the prices will actually have had over the interval $[t,T]$) may be much higher than historical levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Implied Volatility\n",
    "To fix these issues, models could be developed for different possible conditions companies are in, and investors will generally buy and sell options based on the volatility they (or their models) think the underlying assets prices will have. Overall, we would expect prices to differ from the prices predicted when using historic volatility in various ways across different assets. \n",
    "\n",
    "Exercise 1: Show that call option prices are increasing and continuous with respect to volatility.\n",
    "\n",
    "Now we state the put-call parity formula:\n",
    "\n",
    "$$ P_t - C_t = Ke^{-r(T-t)} - S_t$$\n",
    "\n",
    "Where $P_t$ is the price of a put option at time $t$, and $C_t$ is the price of a call option at time $t$ (Both options with strike K and time to expiry $T$). \n",
    "\n",
    "Exercise 2: Use the Put-Call parity formula to show that put option prices are also increasing and continuous with respect to volatility.\n",
    "\n",
    "As option prices are increasing and continuous with respect to volatility, we can find (for any parameters of the option) the unique volatility $\\sigma_1$ which, when put into the Black-Scholes formula, gives the price we can buy the option for on the market. This volatility $\\sigma_1$ is known as the implied volatility (IV) of that option and is the focus of this project. Note that different options can have different strikes and expiration dates and will naturally have different prices. This can lead to (sometimes vastly) different implied volatilities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - The Volatility Surface\n",
    "As the implied volatility can be different for different options, one may wish to get a full picture and use all of the data available on the options chain (an options chain is the listing of all option contracts for a particular underlying asset. It's usually split into calls and puts). This gives a better idea of how investors might expect volatility to change over time, and in what ways the stock may be more or less likely to move. As there are many strikes and expiration dates (often well over 100) it is difficult to see this when presented as a table. \n",
    "\n",
    "Some trading strategies look at a particular portion (i.e. same strike price, different times to expiration, or same expiration date for a range of strikes) to make it easier to spot patterns by focusing on a subset of the data. To see how the implied volatility changes with respect to both the strike price and the time to expiry, one can plot it as a 3D surface with:\n",
    "- Implied Volatilities as the z axis (generally plots are oriented so the positive z axis is \"up\")\n",
    "- Time to maturity as the x axis\n",
    "- Strike price as the y axis\n",
    "One can then see the surface and interpret it much more easily at a glance. Our main goal for this project is to make a program that produces plots of a volatility surface for a given underlying asset based on the options chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Getting Options chains\n",
    "To produce the volatility surface plot, we need implied volatilities. To get implied volatilities, we need to know the market prices of the options. We will do this using the Python library _yfinance_. This allows us to easily access market data provided freely by [Yahoo Finance](https://uk.finance.yahoo.com/). We will now cover briefly some of the data we can obtain with yfinance.\n",
    "\n",
    "## 3.1 - Exploring yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.40\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# Checking version of yfinance. We want the most recent version (at time of writing, 0.2.40)\n",
    "print(yf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-06 00:00:00-04:00</th>\n",
       "      <td>205.062641</td>\n",
       "      <td>209.747221</td>\n",
       "      <td>200.837536</td>\n",
       "      <td>206.990402</td>\n",
       "      <td>69660500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07 00:00:00-04:00</th>\n",
       "      <td>206.660786</td>\n",
       "      <td>213.392999</td>\n",
       "      <td>206.151381</td>\n",
       "      <td>209.577423</td>\n",
       "      <td>63516400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 00:00:00-04:00</th>\n",
       "      <td>212.863619</td>\n",
       "      <td>213.952355</td>\n",
       "      <td>208.588569</td>\n",
       "      <td>213.063385</td>\n",
       "      <td>47161100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-09 00:00:00-04:00</th>\n",
       "      <td>211.854792</td>\n",
       "      <td>216.529374</td>\n",
       "      <td>211.724938</td>\n",
       "      <td>215.990005</td>\n",
       "      <td>42201600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-12 00:00:00-04:00</th>\n",
       "      <td>216.070007</td>\n",
       "      <td>219.509995</td>\n",
       "      <td>215.600006</td>\n",
       "      <td>217.529999</td>\n",
       "      <td>37992400</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-08-06 00:00:00-04:00  205.062641  209.747221  200.837536  206.990402   \n",
       "2024-08-07 00:00:00-04:00  206.660786  213.392999  206.151381  209.577423   \n",
       "2024-08-08 00:00:00-04:00  212.863619  213.952355  208.588569  213.063385   \n",
       "2024-08-09 00:00:00-04:00  211.854792  216.529374  211.724938  215.990005   \n",
       "2024-08-12 00:00:00-04:00  216.070007  219.509995  215.600006  217.529999   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-08-06 00:00:00-04:00  69660500       0.00           0.0  \n",
       "2024-08-07 00:00:00-04:00  63516400       0.00           0.0  \n",
       "2024-08-08 00:00:00-04:00  47161100       0.00           0.0  \n",
       "2024-08-09 00:00:00-04:00  42201600       0.00           0.0  \n",
       "2024-08-12 00:00:00-04:00  37992400       0.25           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we set up a yfinance Ticker object for a given ticker:\n",
    "ticker = \"AAPL\"\n",
    "aapl = yf.Ticker(ticker)\n",
    "\n",
    "# This shows the OHLC data for the most recent 5 trading days, as well as the volume, dividends paid and any stock splits.\n",
    "aapl.history(period = \"5d\")\n",
    "\n",
    "# One can use other periods, i.e. period = \"1mo\" gives the past month of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-12 00:00:00-04:00</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dividends  Stock Splits\n",
       "Date                                              \n",
       "2024-08-12 00:00:00-04:00       0.25           0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get data about stock splits, dividends an other information relating to the stock.\n",
    "\n",
    "# aapl.actions - information on actions that have occurred (both stock splits and dividends),\n",
    "\n",
    "# aapl.dividends - just the dividend information\n",
    "\n",
    "# aapl.splits - just the stock split information.\n",
    "\n",
    "aapl.actions # Note: there may be no actions in the past 5 days, so this is likely to be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-10 00:00:00-05:00</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-09 00:00:00-05:00</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-10 00:00:00-04:00</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-12 00:00:00-04:00</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dividends  Stock Splits\n",
       "Date                                              \n",
       "2023-11-10 00:00:00-05:00       0.24           0.0\n",
       "2024-02-09 00:00:00-05:00       0.24           0.0\n",
       "2024-05-10 00:00:00-04:00       0.25           0.0\n",
       "2024-08-12 00:00:00-04:00       0.25           0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see actions in the past year, we can do:\n",
    "aapl.history(period = \"1y\")\n",
    "aapl.actions\n",
    "\n",
    "# To get dividends, use aapl.dividends, \n",
    "# To get splits, use aapl.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currency': 'USD',\n",
       " 'symbol': 'AAPL',\n",
       " 'exchangeName': 'NMS',\n",
       " 'fullExchangeName': 'NasdaqGS',\n",
       " 'instrumentType': 'EQUITY',\n",
       " 'firstTradeDate': 345479400,\n",
       " 'regularMarketTime': 1723492802,\n",
       " 'hasPrePostMarketData': True,\n",
       " 'gmtoffset': -14400,\n",
       " 'timezone': 'EDT',\n",
       " 'exchangeTimezoneName': 'America/New_York',\n",
       " 'regularMarketPrice': 217.53,\n",
       " 'fiftyTwoWeekHigh': 219.51,\n",
       " 'fiftyTwoWeekLow': 215.6,\n",
       " 'regularMarketDayHigh': 219.51,\n",
       " 'regularMarketDayLow': 215.6,\n",
       " 'regularMarketVolume': 37581880,\n",
       " 'longName': 'Apple Inc.',\n",
       " 'shortName': 'Apple Inc.',\n",
       " 'chartPreviousClose': 177.79,\n",
       " 'priceHint': 2,\n",
       " 'currentTradingPeriod': {'pre': {'timezone': 'EDT',\n",
       "   'end': 1723555800,\n",
       "   'start': 1723536000,\n",
       "   'gmtoffset': -14400},\n",
       "  'regular': {'timezone': 'EDT',\n",
       "   'end': 1723579200,\n",
       "   'start': 1723555800,\n",
       "   'gmtoffset': -14400},\n",
       "  'post': {'timezone': 'EDT',\n",
       "   'end': 1723593600,\n",
       "   'start': 1723579200,\n",
       "   'gmtoffset': -14400}},\n",
       " 'dataGranularity': '1d',\n",
       " 'range': '1y',\n",
       " 'validRanges': ['1d',\n",
       "  '5d',\n",
       "  '1mo',\n",
       "  '3mo',\n",
       "  '6mo',\n",
       "  '1y',\n",
       "  '2y',\n",
       "  '5y',\n",
       "  '10y',\n",
       "  'ytd',\n",
       "  'max']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get metadata about the stock:\n",
    "aapl.history_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'uuid': '2a2e362b-a1b1-3e84-aca1-2bf3d75ffff1',\n",
       "  'title': 'India Watchdog to Withdraw Report Accusing Apple of Market Abuse',\n",
       "  'publisher': 'Bloomberg',\n",
       "  'link': 'https://finance.yahoo.com/news/india-watchdog-withdraw-report-accusing-064652406.html',\n",
       "  'providerPublishTime': 1723531612,\n",
       "  'type': 'STORY',\n",
       "  'thumbnail': {'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/FXhUwLozPMyzIq7L_5rHng--~B/aD0xMzM2O3c9MjAwMDthcHBpZD15dGFjaHlvbg--/https://media.zenfs.com/en/bloomberg_technology_68/28594f5d8a097fc23c705834b9e61ecc',\n",
       "     'width': 2000,\n",
       "     'height': 1336,\n",
       "     'tag': 'original'},\n",
       "    {'url': 'https://s.yimg.com/uu/api/res/1.2/_rBK7yuZWnApGSsxlXEGbg--~B/Zmk9ZmlsbDtoPTE0MDtweW9mZj0wO3c9MTQwO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/bloomberg_technology_68/28594f5d8a097fc23c705834b9e61ecc',\n",
       "     'width': 140,\n",
       "     'height': 140,\n",
       "     'tag': '140x140'}]},\n",
       "  'relatedTickers': ['AAPL']},\n",
       " {'uuid': 'b8dec341-8699-357a-bbb1-2795a1851c85',\n",
       "  'title': 'Buy the Tech Dip for the AI Bull Cycle',\n",
       "  'publisher': 'Zacks',\n",
       "  'link': 'https://finance.yahoo.com/news/buy-tech-dip-ai-bull-220500606.html',\n",
       "  'providerPublishTime': 1723500300,\n",
       "  'type': 'STORY',\n",
       "  'thumbnail': {'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/9luckxOk8kuyxVFOBDXD7g--~B/aD0zNDk7dz02MjA7YXBwaWQ9eXRhY2h5b24-/https://media.zenfs.com/en/zacks.com/80c3b0044109952d2ccd07e54852806c',\n",
       "     'width': 620,\n",
       "     'height': 349,\n",
       "     'tag': 'original'},\n",
       "    {'url': 'https://s.yimg.com/uu/api/res/1.2/RCFht.LXTkGpxWL7m1KW4A--~B/Zmk9ZmlsbDtoPTE0MDtweW9mZj0wO3c9MTQwO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/zacks.com/80c3b0044109952d2ccd07e54852806c',\n",
       "     'width': 140,\n",
       "     'height': 140,\n",
       "     'tag': '140x140'}]},\n",
       "  'relatedTickers': ['GOOG', 'TSLA', 'AAPL', 'NVDA']},\n",
       " {'uuid': 'ef5f7000-c3a3-3007-a4d2-de1ae244b5c9',\n",
       "  'title': 'Are Magnificent 7 valuations attractive again?',\n",
       "  'publisher': 'Yahoo Finance Video',\n",
       "  'link': 'https://finance.yahoo.com/video/magnificent-7-valuations-attractive-again-215617403.html',\n",
       "  'providerPublishTime': 1723499777,\n",
       "  'type': 'VIDEO',\n",
       "  'thumbnail': {'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/Ui3u75mZwQJ7wMceo2FDjQ--~B/aD0yOTg3O3c9NTMxNTthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2024-08/10b450f0-58f1-11ef-a777-cfaf814b171a',\n",
       "     'width': 5315,\n",
       "     'height': 2987,\n",
       "     'tag': 'original'},\n",
       "    {'url': 'https://s.yimg.com/uu/api/res/1.2/46SGP60ClHCZ_YTdf_aqnw--~B/Zmk9ZmlsbDtoPTE0MDtweW9mZj0wO3c9MTQwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2024-08/10b450f0-58f1-11ef-a777-cfaf814b171a',\n",
       "     'width': 140,\n",
       "     'height': 140,\n",
       "     'tag': '140x140'}]},\n",
       "  'relatedTickers': ['AAPL',\n",
       "   'MSFT',\n",
       "   'AMZN',\n",
       "   'NVDA',\n",
       "   'GOOG',\n",
       "   'XLK',\n",
       "   'META',\n",
       "   'TSLA']},\n",
       " {'uuid': '7c713d88-892f-3e31-a36a-af62753a6caa',\n",
       "  'title': 'Apple says Patreon must switch to its billing system or risk removal from App Store',\n",
       "  'publisher': 'TechCrunch',\n",
       "  'link': 'https://finance.yahoo.com/m/7c713d88-892f-3e31-a36a-af62753a6caa/apple-says-patreon-must.html',\n",
       "  'providerPublishTime': 1723499350,\n",
       "  'type': 'STORY',\n",
       "  'relatedTickers': ['AAPL']},\n",
       " {'uuid': '124370af-a979-31fb-9fcc-5e4bae2587c5',\n",
       "  'title': 'Patreon Says It Must Use Appleâ€™s Payment System Or Risk Removal',\n",
       "  'publisher': 'The Information',\n",
       "  'link': 'https://finance.yahoo.com/m/124370af-a979-31fb-9fcc-5e4bae2587c5/patreon-says-it-must-use.html',\n",
       "  'providerPublishTime': 1723495436,\n",
       "  'type': 'STORY',\n",
       "  'thumbnail': {'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/yAxqQNZ58IodHspU8s6dNQ--~B/aD03MjI7dz0xMjg0O2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/the_information_premium_news_383/d64b01c3c184d8f3156693c5c04855dd',\n",
       "     'width': 1284,\n",
       "     'height': 722,\n",
       "     'tag': 'original'},\n",
       "    {'url': 'https://s.yimg.com/uu/api/res/1.2/51YEkEZxAu.OL299.PIpaw--~B/Zmk9ZmlsbDtoPTE0MDtweW9mZj0wO3c9MTQwO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/the_information_premium_news_383/d64b01c3c184d8f3156693c5c04855dd',\n",
       "     'width': 140,\n",
       "     'height': 140,\n",
       "     'tag': '140x140'}]},\n",
       "  'relatedTickers': ['AAPL']},\n",
       " {'uuid': '2915b816-5d29-392a-abfc-2b3f7d6b80bc',\n",
       "  'title': \"Wolfe Research downgrades Qualcomm over Apple's chip plans\",\n",
       "  'publisher': 'Yahoo Finance Video',\n",
       "  'link': 'https://finance.yahoo.com/video/wolfe-research-downgrades-qualcomm-over-201127598.html',\n",
       "  'providerPublishTime': 1723493487,\n",
       "  'type': 'VIDEO',\n",
       "  'thumbnail': {'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/WWwShbyKF0beh2CUmW2FVg--~B/aD0yMzQyO3c9NDE3MDthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2024-08/035cd580-58e7-11ef-97ff-2a766ae68690',\n",
       "     'width': 4170,\n",
       "     'height': 2342,\n",
       "     'tag': 'original'},\n",
       "    {'url': 'https://s.yimg.com/uu/api/res/1.2/irxLhy8YXBtcPYd0btD30w--~B/Zmk9ZmlsbDtoPTE0MDtweW9mZj0wO3c9MTQwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2024-08/035cd580-58e7-11ef-97ff-2a766ae68690',\n",
       "     'width': 140,\n",
       "     'height': 140,\n",
       "     'tag': '140x140'}]},\n",
       "  'relatedTickers': ['QCOM', 'AAPL']},\n",
       " {'uuid': '2e36fa10-b612-3c4b-b744-d22d8b0d4a00',\n",
       "  'title': 'Sector Update: Tech Stocks Mixed Late Afternoon',\n",
       "  'publisher': 'MT Newswires',\n",
       "  'link': 'https://finance.yahoo.com/news/sector-tech-stocks-mixed-afternoon-195525484.html',\n",
       "  'providerPublishTime': 1723492525,\n",
       "  'type': 'STORY',\n",
       "  'relatedTickers': ['AAPL']},\n",
       " {'uuid': '4205eaa9-f620-3a0b-a81a-0e82c7c9fd0b',\n",
       "  'title': 'Magnificent Seven Stocks: Nvidia Stock Rallies; Tesla Slides',\n",
       "  'publisher': \"Investor's Business Daily\",\n",
       "  'link': 'https://finance.yahoo.com/m/4205eaa9-f620-3a0b-a81a-0e82c7c9fd0b/magnificent-seven-stocks%3A.html',\n",
       "  'providerPublishTime': 1723483962,\n",
       "  'type': 'STORY',\n",
       "  'thumbnail': {'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/kV2Fc5Kz3y8hNbXlVxHRQg--~B/aD01NjU7dz0xMDAwO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/ibd.com/d5bee44b5deef90ccff5d488feb6722d',\n",
       "     'width': 1000,\n",
       "     'height': 565,\n",
       "     'tag': 'original'},\n",
       "    {'url': 'https://s.yimg.com/uu/api/res/1.2/My3O.I831YydYsn.iMoUvw--~B/Zmk9ZmlsbDtoPTE0MDtweW9mZj0wO3c9MTQwO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/ibd.com/d5bee44b5deef90ccff5d488feb6722d',\n",
       "     'width': 140,\n",
       "     'height': 140,\n",
       "     'tag': '140x140'}]},\n",
       "  'relatedTickers': ['NVDA', 'AAPL', 'TSLA', 'META', 'MSFT']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get data about the current major holders of the stock:\n",
    "aapl.institutional_holders # major institutional holders\n",
    "\n",
    "# Lastly, one can get recent news articles relating to the stock with .news\n",
    "aapl.news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've covered some basic functionality of yfinance, we will move on to the main part we need for this project, getting options chain data. _aapl.options_ gives the expiry dates of AAPL options that yfinance has data for. We can then get an option chain for a specific expiry date using the _.option_chain()_ function, which takes as input the expiry date we're interested in getting the option chain for. \n",
    "\n",
    "We want to get all the data yfinance has, so we will loop over all the expiry dates it has information for and get the option chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-16\n"
     ]
    }
   ],
   "source": [
    "# Exploration\n",
    "expiry_dates = aapl.options\n",
    "print(expiry_dates[0])\n",
    "first_option_chain = aapl.option_chain(expiry_dates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option chain is a tuple object, with entries:\n",
    "\n",
    "_(call_data_frame, put_data_frame, general_information_dictionary)_\n",
    "\n",
    "we can access each of these with first_option_chain[i] for different values of i.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractSymbol</th>\n",
       "      <th>lastTradeDate</th>\n",
       "      <th>strike</th>\n",
       "      <th>lastPrice</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>change</th>\n",
       "      <th>percentChange</th>\n",
       "      <th>volume</th>\n",
       "      <th>openInterest</th>\n",
       "      <th>impliedVolatility</th>\n",
       "      <th>inTheMoney</th>\n",
       "      <th>contractSize</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AAPL240816C00165000</td>\n",
       "      <td>2024-08-09 18:04:57+00:00</td>\n",
       "      <td>165.0</td>\n",
       "      <td>50.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AAPL240816C00170000</td>\n",
       "      <td>2024-08-12 18:17:48+00:00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AAPL240816C00175000</td>\n",
       "      <td>2024-08-12 19:38:02+00:00</td>\n",
       "      <td>175.0</td>\n",
       "      <td>42.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AAPL240816C00180000</td>\n",
       "      <td>2024-08-12 19:02:20+00:00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>37.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AAPL240816C00185000</td>\n",
       "      <td>2024-08-12 19:26:59+00:00</td>\n",
       "      <td>185.0</td>\n",
       "      <td>32.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AAPL240816C00187500</td>\n",
       "      <td>2024-08-12 15:36:18+00:00</td>\n",
       "      <td>187.5</td>\n",
       "      <td>30.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AAPL240816C00190000</td>\n",
       "      <td>2024-08-12 18:55:51+00:00</td>\n",
       "      <td>190.0</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AAPL240816C00195000</td>\n",
       "      <td>2024-08-12 19:53:14+00:00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AAPL240816C00197500</td>\n",
       "      <td>2024-08-12 14:49:04+00:00</td>\n",
       "      <td>197.5</td>\n",
       "      <td>21.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AAPL240816C00200000</td>\n",
       "      <td>2024-08-12 19:58:06+00:00</td>\n",
       "      <td>200.0</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         contractSymbol             lastTradeDate  strike  lastPrice  bid  \\\n",
       "20  AAPL240816C00165000 2024-08-09 18:04:57+00:00   165.0      50.89  0.0   \n",
       "21  AAPL240816C00170000 2024-08-12 18:17:48+00:00   170.0      47.00  0.0   \n",
       "22  AAPL240816C00175000 2024-08-12 19:38:02+00:00   175.0      42.08  0.0   \n",
       "23  AAPL240816C00180000 2024-08-12 19:02:20+00:00   180.0      37.47  0.0   \n",
       "24  AAPL240816C00185000 2024-08-12 19:26:59+00:00   185.0      32.38  0.0   \n",
       "25  AAPL240816C00187500 2024-08-12 15:36:18+00:00   187.5      30.21  0.0   \n",
       "26  AAPL240816C00190000 2024-08-12 18:55:51+00:00   190.0      27.50  0.0   \n",
       "27  AAPL240816C00195000 2024-08-12 19:53:14+00:00   195.0      22.00  0.0   \n",
       "28  AAPL240816C00197500 2024-08-12 14:49:04+00:00   197.5      21.77  0.0   \n",
       "29  AAPL240816C00200000 2024-08-12 19:58:06+00:00   200.0      17.36  0.0   \n",
       "\n",
       "    ask  change  percentChange  volume  openInterest  impliedVolatility  \\\n",
       "20  0.0     0.0            0.0       4             0            0.00001   \n",
       "21  0.0     0.0            0.0     100             0            0.00001   \n",
       "22  0.0     0.0            0.0     119             0            0.00001   \n",
       "23  0.0     0.0            0.0      86             0            0.00001   \n",
       "24  0.0     0.0            0.0     268             0            0.00001   \n",
       "25  0.0     0.0            0.0       1             0            0.00001   \n",
       "26  0.0     0.0            0.0     643             0            0.00001   \n",
       "27  0.0     0.0            0.0     199             0            0.00001   \n",
       "28  0.0     0.0            0.0     104             0            0.00001   \n",
       "29  0.0     0.0            0.0    5557             0            0.00001   \n",
       "\n",
       "    inTheMoney contractSize currency  \n",
       "20        True      REGULAR      USD  \n",
       "21        True      REGULAR      USD  \n",
       "22        True      REGULAR      USD  \n",
       "23        True      REGULAR      USD  \n",
       "24        True      REGULAR      USD  \n",
       "25        True      REGULAR      USD  \n",
       "26        True      REGULAR      USD  \n",
       "27        True      REGULAR      USD  \n",
       "28        True      REGULAR      USD  \n",
       "29        True      REGULAR      USD  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To access the call part of the data, we can use\n",
    "first_option_chain[0].head(5)\n",
    "# or\n",
    "first_option_chain.calls[20:30]\n",
    "# (And similarly for the puts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm everything is functioning as intended, we can compare these values to an alternative data source. We check our prices against the Nasdaq website's AAPL option chain data, which can be found [here](https://www.nasdaq.com/market-activity/stocks/aapl/option-chain). We can see that the most recent prices are the same, and the dates / times to expiry also match up, confirming that the yfinance data is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTE</th>\n",
       "      <th>Expiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-08-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DTE Expiration\n",
       "0   10 2024-08-23\n",
       "1   10 2024-08-23\n",
       "2   10 2024-08-23\n",
       "3   10 2024-08-23\n",
       "4   10 2024-08-23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a boolean variable for whether an option is a put or a call:\n",
    "call_df = first_option_chain.calls\n",
    "put_df = first_option_chain.puts\n",
    "call_df[\"call\"] = True\n",
    "put_df[\"call\"] = False\n",
    "\n",
    "# Combining the options chains dataframes into one:\n",
    "full_chain_data = pd.concat([call_df, put_df])\n",
    "\n",
    "# Converting the date into a datetime object so we can modify it, and then storing it in our dataframe:\n",
    "full_chain_data[\"Expiration\"] = pd.to_datetime(expiry_dates[1])\n",
    "\n",
    "# Saving the number of days until it expires:\n",
    "full_chain_data[\"DTE\"] = (full_chain_data[\"Expiration\"] - datetime.datetime.today()).dt.days + 1\n",
    "# Note: DTE is the number of days until expiry, but .dt.days only includes the whole number of days until expiry.\n",
    "# Therefore, if we don't add the 1:\n",
    "# if the current day is the 5th, and the option expires on the 10th there are 4 whole days until expiry \n",
    "# (and some portion of another day) so DTE is set to 4. It makes more sense for this to be set to 5 instead.\n",
    "\n",
    "# Checking the results:\n",
    "full_chain_data[[\"DTE\", \"Expiration\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_data = pd.DataFrame()\n",
    "for expiry in expiry_dates:\n",
    "    # Getting the option chain for the current expiry\n",
    "    current_option_chain = aapl.option_chain(expiry)\n",
    "    call_df = current_option_chain.calls\n",
    "    put_df = current_option_chain.puts\n",
    "    call_df[\"call\"] = True\n",
    "    put_df[\"call\"] = False\n",
    "\n",
    "    # Reformatting it to be a single data frame:\n",
    "    current_option_chain = pd.concat([call_df, put_df])\n",
    "    current_option_chain[\"Expiration\"] = pd.to_datetime(expiry)\n",
    "    # current_option_chain[\"DTE\"] = (full_chain_data[\"Expiration\"] - datetime.datetime.today()).dt.days\n",
    "    options_data = pd.concat([options_data, current_option_chain])\n",
    "\n",
    "options_data[\"DTE\"] = (options_data[\"Expiration\"] - datetime.datetime.today()).dt.days\n",
    "# Note: DTE is the number of whole days until expiry. For instance, if the current day is the 5th, and the option expires on the 10th, \n",
    "# there are 4 whole days until expiry (and some portion of another day) so DTE is set to 4.\n",
    "\n",
    "# Lastly, we remove some columns we no longer need:\n",
    "options_data = options_data.drop(columns = [\"contractSize\",\"currency\",\"percentChange\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - A function to gather options chains\n",
    "We may need to gather this option chain data for different tickers, so it makes sense to make our code into a function we can call to retrieve the full data frame of options data. \n",
    "\n",
    "Exercise 3: Finish the following function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options_data(ticker):\n",
    "    # A function that takes as input a string corresponding to a stock ticker, and outputs a dataframe containing\n",
    "    # all of the yfinance options data for that ticker.\n",
    "\n",
    "    # Getting the ticker object and the dates to loop over\n",
    "    yf_ticker = yf.Ticker(ticker)\n",
    "    expiry_dates = yf_ticker.options\n",
    "\n",
    "    # Container to store the data.\n",
    "    options_data = pd.DataFrame()\n",
    "    \n",
    "    # TODO Exercise 3 starts here: \n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # End of Exercise.\n",
    "\n",
    "    options_data[\"DTE\"] = (options_data[\"Expiration\"] - datetime.datetime.today()).dt.days + 1 # We add one as dt.days rounds down\n",
    "    options_data = options_data.drop(columns = [\"contractSize\",\"currency\",\"percentChange\"])\n",
    "    return(options_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our code works:\n",
    "aapl_df = get_options_data(\"AAPL\")\n",
    "aapl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Computing the Implied Volatility\n",
    "\n",
    "## 4.1 - Motivation\n",
    "As discussed in Part 1, now that we have the options data we need to compute the implied volatility. If you were looking closely in the previous few sections, you may have noticed that yfinance reports the implied volatility of the options. One could simply use this to plot the volatility surface and skip this section entirely. However:\n",
    "- What if you wanted to plot the volatility surface when using a different pricing model (e.g. the Bachelier model - see the extensions)?\n",
    "- What if you needed to get a fast, approximate value for an implied volatility?\n",
    "- What if the provider in a particular market didn't give implied volatilities for the assets you wished to trade with?\n",
    "- How are you sure the providers implied volatilities are correct?\n",
    "\n",
    "and of course, the process of computing implied volatilities is quite interesting. It's a relatively simple problem to understand, but there are many different approaches to get accurate and fast estimates of the implied volatility.\n",
    "\n",
    "In Part 1 we noted that:\n",
    "1. The implied volatility $\\sigma_1$ is the volatility such that the Black-Scholes price of the option is equal to the current market price\n",
    "2. The Black-Scholes price of an option is continuous and increasing as the volatility changes (when the other parameters are fixed).\n",
    "therefore, if we write $f(\\sigma)$ as the Black-Scholes price of an option with time $t$ price $S_t$, strike $K$, expiration time/date $T$, risk-free rate $r$ and volatility $\\sigma$, the implied volatility $\\sigma_1$ is the (unique from 2.) value such that $f(\\sigma_1) = V$ where $V$ is the market price of the option.\n",
    "\n",
    "In other words, we have to solve for the root $\\sigma_1$ of the equation $f(\\sigma)-V$. We will cover a few methods to do this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Analytic solution:\n",
    "Unfortunately, there is no known closed form solution to this problem in the general case, as there is no known way to invert the function $f$\n",
    "$$f(\\sigma) = S_t \\times \\Phi(d_1(\\sigma)) - K \\times \\Phi(d_2(\\sigma)) e^{-r(T-t)}$$\n",
    "where $\\Phi$ is the cumulative distribution function of a standard normal random variable and:\n",
    "\n",
    "$$ d_1 = \\frac{1}{\\sigma \\sqrt{T-t}} \\left\\{ ln\\left(\\frac{S_t}{K}\\right) + \\left(r + \\frac{\\sigma^2}{2}\\right)(T-t)\\right\\}$$\n",
    "\n",
    "$$ d_2 =  \\frac{1}{\\sigma \\sqrt{T-t}} \\left\\{ ln\\left(\\frac{S_t}{K}\\right) + \\left(r - \\frac{\\sigma^2}{2}\\right)(T-t)\\right\\}$$\n",
    "\n",
    "Exercise 4: Find an expression (in terms of the inverse of $\\Phi$) for the inverse in the special case where $K = S_t e^{r(T-t)}$. Do this exercise before proceeding as the next part contains spoilers. \n",
    "\n",
    "Now we don't have a closed form for $\\Phi^{-1}$ either, which poses an issue. If a loss in accuracy is acceptable, one can use a Taylor expansion on $\\Phi$ and determine a fully closed form approximation to the implied volatility that works for small values of $\\sigma \\sqrt{T-t}$ and is very simple.\n",
    "\n",
    "---(SPOLIERS FOR EXERCISE 3 AHEAD)---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2.1 - Analytical approximation of IV (for ATM options)\n",
    "We have $S = K e^{-r(T-t)}$ so, using the same approach as in Exercise 3, we can simplify our expressions for $d_1$ and $d_2$ to get $d_1(\\sigma) = \\sigma/2* \\sqrt{T-t}$ and $d_2(\\sigma) = -\\sigma/2* \\sqrt{T-t}$. Then our expression for the call price becomes:\n",
    "\n",
    "$$C(S_t,t) = \\Phi(d_1) S - \\Phi(d_2) K e^{-r(T-t)} = \\Phi(\\sigma/2* \\sqrt{T-t}) S - \\Phi(-\\sigma/2* \\sqrt{T-t}) K e^{-r(T-t)} $$ \n",
    "\n",
    "To deal with $\\Phi$, which we cannot analyitcally invert, we will assume that $\\sigma/2* \\sqrt{T-t}$ is small enough that a Taylor expansion of $\\Phi$ around $0$ is valid. We note that:\n",
    "- $\\Phi(0) = 1/2$\n",
    "- $\\Phi'(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$ and substituting in $0$ we get $\\Phi'(0) = \\frac{1}{\\sqrt{2\\pi}}$\n",
    "- $\\Phi''(x) = \\frac{1}{\\sqrt{2\\pi}} \\times -xe^{-x^2/2}$ and substituting in 0 we get $\\Phi''(0) = 0$\n",
    "\n",
    "Taylor's formula applied to $\\Phi$ gives that for $x$ near $0$:\n",
    "\n",
    "$$\\Phi(x) = \\Phi(0) + x \\Phi'(0) + \\frac{x^2}{2} \\Phi''(0) + O(x^3) = 0.5 + \\frac{1}{\\sqrt{2\\pi}} x + 0 + O(x^3)$$\n",
    "\n",
    "We now apply this to our expression for the call price and get:\n",
    "\n",
    "$$C(S_t, t) \\approx \\frac{S}{2} + \\frac{S\\sigma \\sqrt{T-t}}{2*\\sqrt{2\\pi}} - \\frac{Ke^{-r(T-t)}}{2} + \\frac{Ke^{-r(T-t)} \\sigma\\sqrt{T-t}}{2*\\sqrt{2\\pi}}$$\n",
    "\n",
    "And now applying $S = K e^{-r(T-t)}$ gives:\n",
    "\n",
    "$$C(S_t, t) \\approx \\frac{S\\sigma \\sqrt{T-t}}{2*\\sqrt{2\\pi}}  + \\frac{S \\sigma\\sqrt{T-t}}{2*\\sqrt{2\\pi}} =\\frac{S \\sigma\\sqrt{T-t}}{\\sqrt{2\\pi}}$$\n",
    "\n",
    "Rearranging for $\\sigma$ gives:\n",
    "\n",
    "$$\\sigma \\approx \\sqrt{\\frac{2\\pi}{T-t}} \\frac{C}{S}$$\n",
    "\n",
    "For computing this in your head or on paper, note that $\\sqrt{2\\pi} \\approx 2.5$, so we get a loose approximation of the IV of: $2.5 \\times \\frac{\\text{option price}}{\\text{stock price} \\times \\text{sqrt(time to expiry)}}$\n",
    "\n",
    "This approximation was first derived by Brenner and Subrahmanyam in 1988. Corrado and Miller expanded this to cover when stock prices deviate from discounted strikes in 1996, and more recently even more accurate approximations have been discovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Numerical Methods\n",
    "In the general it is not at all clear how to invert $f$ and find a exact closed form expression for $\\sigma$ in terms of $V$. We will instead attempt to find a numerical approximation to this problem.\n",
    "\n",
    "We will consider the following root finding algorithms:\n",
    "- The bisection method (a reliable but slow method)\n",
    "- The Newton-Raphson method (and an extension to it)\n",
    "- Brent's method (a widely used root finding algorithm)\n",
    "\n",
    "These can all be applied generally to other problems where one needs to find the zeros of a (sufficiently well behaved) function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 - Getting the price for a given volatility\n",
    "On top of there not being a closed form solution, we have another issue. $\\Phi$, the CDF of a $N(0,1)$ random variable, is given by:\n",
    "\n",
    "$$ \\Phi(x) = \\int_{-\\infty}^x e^{-u^2/2}du$$\n",
    "\n",
    "This is problematic because the right hand side is an integral, not a combination of analytic functions. This means that to get values of $\\Phi$ we either need to:\n",
    "- Use some sort of integration method to compute values of $\\Phi$.\n",
    "- Use some approximation of the true value of $\\Phi$ derived mathematically.\n",
    "\n",
    "For those interested in approximations to the normal CDF, a paper providing a good overview and a practical approach to accurate approximations to the normal CDF can be found here: [Approximating the cumulative distribution function of the normal distribution](http://jsr.isrt.ac.bd/wp-content/uploads/41n1_5.pdf).\n",
    "\n",
    "In the name of conciseness, we will use the SciPy normal CDF, which approximates $\\Phi$ to a high accuracy. It relies upon the Cephes Math Library's implementation of the inverse of the logarithm of the CDF of the standard normal distribution. To get this cdf, we use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Setting up plotly for plotting in a Jupyter Notebook\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True) \n",
    "import numpy as np\n",
    "Phi = norm.cdf\n",
    "x = np.linspace(-6,6, 100)\n",
    "y = Phi(x)\n",
    "y[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(data = go.Scatter(x=x, y=Phi(x)))\n",
    "fig.update_layout(title=\"Graph of Phi, the standard normal CDF\", \n",
    "                  yaxis_title = \"Phi(x)\",\n",
    "                  xaxis_title = \"x\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the derivative of the Black-Scholes price with respect to $\\sigma$ (which we'll need for some of the methods) there is a nice closed form which can be written in terms of the pdf of a N(0,1) random variable. To confirm this, look at your solution to Exercise 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_Phi = norm.pdf\n",
    "print(f\"SciPy implementation: {deriv_Phi(0.1)}\")\n",
    "print(f\"Test implementation: {1/np.sqrt(2*np.pi)* np.exp(-0.5 * 0.1**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to actually code the Black-Scholes price (and it's derivative) so we can call them for root finding methods. \n",
    "\n",
    "Exercise 5: Finish the code for the Black-Scholes put price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_call_price(vol, time_to_expiry, strike_price, current_price, risk_free):\n",
    "    d_1 = 1/vol * 1/np.sqrt(time_to_expiry) * (np.log(current_price/strike_price) + (risk_free + vol**2/2) * time_to_expiry)\n",
    "    d_2 = d_1 - vol * np.sqrt(time_to_expiry)\n",
    "    term_1 = current_price * Phi(d_1)\n",
    "    term_2 = strike_price * np.exp(-risk_free * time_to_expiry) * Phi(d_2)\n",
    "    return term_1 - term_2\n",
    "\n",
    "\n",
    "def black_scholes_put_price(vol, time_to_expiry, strike_price, current_price, risk_free):\n",
    "    # TODO - Exercise 5 starts here:\n",
    "    # -----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # End of Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your implementation\n",
    "vol = np.array([0.1,0.55,1,2.5]) #0.55 here corresponds to 55% volatility\n",
    "time_to_expiry = np.array([5,4,3,2]) # in years\n",
    "strike_price = np.array([20,22.5,25,27.5]) # Â£ or $\n",
    "current_price = 10 # $ or Â£\n",
    "risk_free = 0.04 # 0.04 corresponds to 4% per year\n",
    "\n",
    "prices = black_scholes_put_price(vol, time_to_expiry, strike_price, current_price, risk_free)\n",
    "print(prices)\n",
    "# If everything is working this should be small (on the order of 10^-6). If not, check your function is correct.\n",
    "np.max(np.abs(prices - np.array([6.38831,11.57596,16.70026,24.18715])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to implement the derivative with respect to the volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_derivative(vol, time_to_expiry, strike_price, current_price, risk_free):\n",
    "    d_1 = 1/vol * 1/np.sqrt(time_to_expiry) * (np.log(current_price/strike_price) + (risk_free + vol**2/2) * time_to_expiry)\n",
    "    derivative = current_price * deriv_Phi(d_1) * np.sqrt(time_to_expiry)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivs = black_scholes_derivative(vol, time_to_expiry, strike_price, current_price, risk_free)\n",
    "\n",
    "# This is also around 10^-6\n",
    "np.max(np.abs(derivs - np.array([0.50264,15.14238,12.06334,3.25995])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have functions to evaluate the Black-Scholes price, and it's derivative with respect to volatility, we are ready to discuss the root finding methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 - The bisection method\n",
    "\n",
    "As the price is continuous and increasing with respect to the volatility, if we can find $\\sigma^{(0)}_- < \\sigma^{(0)}_+$ such that:\n",
    "\n",
    "$$f(\\sigma^{(0)}_-)-V < 0 \\quad \\text{and} \\quad f(\\sigma^{(0)}_+)-V > 0$$\n",
    "\n",
    "then we know that the unique implied volatility is in the interval $[\\sigma^{(0)}_- , \\sigma^{(0)}_+]$. Next, we can pick a point in this interval, $\\sigma_1$, and check whether $f(\\sigma^{(0)}_-)-V$ is positive or negative. If it is positive, then similarly to the above we know the implied volatility is in the interval $[\\sigma^{(1)}_- , \\sigma^{(1)}_+]$ where:\n",
    "\n",
    "$$\\sigma^{(1)}_- = \\sigma^{(0)}_-,\\quad \\sigma^{(1)}_+ = \\sigma_1$$ \n",
    "\n",
    "Similarly, if it is negative then we know the implied volatility is in the interval $[\\sigma^{(1)}_- , \\sigma^{(1)}_+]$ where this time:\n",
    "\n",
    "$$\\sigma^{(1)}_- = \\sigma_1, \\quad \\sigma^{(1)}_+ = \\sigma^{(0)}_+$$ \n",
    "\n",
    "To minimize the size of this range in the worst case, we can choose $\\sigma_i$ to be the midpoint of the previous interval, so:\n",
    "\n",
    "$$\\sigma_{i+1} = \\frac{\\sigma^{(i)}_+ + \\sigma^{(i)}_-}{2}$$\n",
    "\n",
    "Then, to find the root, we repeatedly apply this process, at each step defining $\\sigma_i$ as the midpoint and determining which interval to continue searching in using the same steps as above. Now we will implement this in code. The version we implement is slightly more general, as it works for both decreasing and increasing continuous functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_with_width(FUN, init_lower, init_upper, target_value, width):\n",
    "    \n",
    "    # A function that computes the input value x such that FUN(x) = target_value via a binary search.\n",
    "    # (solution is accurate up to some acceptable width). \n",
    "\n",
    "    # Method is guaranteed to work if the init_lower < true root < init_upper, and the function is continuous.\n",
    "\n",
    "    # Counter to track how many iterations it completes:\n",
    "    counter = 0\n",
    "\n",
    "    # Error detection\n",
    "    if (FUN(init_lower)-target_value) * (FUN(init_upper)-target_value)>0:\n",
    "        return(\"No change of sign in interval\")\n",
    "    \n",
    "    # Running until the interval is within the width specified\n",
    "    while init_upper - init_lower > width:\n",
    "        midpoint = (init_lower + init_upper)/2\n",
    "        # Check which half of the interval the root is in\n",
    "        if (FUN(init_lower)-target_value)* (FUN(midpoint)-target_value)<0:\n",
    "            init_upper = midpoint\n",
    "        else:\n",
    "            init_lower = midpoint\n",
    "        counter+=1\n",
    "    \n",
    "    # |midpoint -init_lower| < 0.5*width (and similarly for init_upper) therefore must be a root in the interval\n",
    "    # (midpoint - 0.5*width, midpoint + 0.5*width)\n",
    "    midpoint = (init_lower + init_upper)/2\n",
    "    return(midpoint, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test our function to ensure it's working as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_polynomial(x):\n",
    "    return(100*x**5 - 4*x**3 + x-1)\n",
    "\n",
    "init_lower = 0\n",
    "init_upper = 100\n",
    "target_value = 13.5\n",
    "acceptable_error = 1e-5\n",
    "root, iterations = bisection_with_width(example_polynomial,init_lower, init_upper, target_value, acceptable_error)\n",
    "print(f\"Using {iterations} iterations, the bisection method found an estimate of the root: {root} accurate up to {acceptable_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that this is a root:\n",
    "example_polynomial(root) - target_value\n",
    "# this is small so our code is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One modification that can be made is to have the tolerance instead apply to the value of the function, ensuring that $|f(x) - V|<\\epsilon$ for some tolerance $\\epsilon$. This can be more useful than the form above as we can specify how large errors are allowed to be. \n",
    "\n",
    "Exercise 6: Finish the code below for a new version of the bisection method where we add a parameter specifying the number of iterations before it should exit the while loop and finish early. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method(FUN, init_lower, init_upper, target_value, tol, max_iterations=250):\n",
    "    \n",
    "    # A function that computes the input value x such that |FUN(x) - target_value|<tol using a binary search.\n",
    "\n",
    "    # Method is guaranteed to work eventually if the init_lower < true root < init_upper, and the function is continuous.\n",
    "    counter = 0\n",
    "    # Error detection\n",
    "    if (FUN(init_lower)-target_value) * (FUN(init_upper)-target_value)>0:\n",
    "        return(\"No change of sign in interval\")\n",
    "\n",
    "    # Running until it reaches the maximum number of iterations or until the function's value is within tol of the target.\n",
    "    midpoint = (init_lower + init_upper)/2\n",
    "\n",
    "    # TODO - Exercise 6 starts here:\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    return(midpoint, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lower = 0\n",
    "init_upper = 100\n",
    "target_value = 13.49546\n",
    "max_iterations = 50\n",
    "# With these values, the method should converge in <40 steps for each value of i.\n",
    "for i in range(8):\n",
    "    acceptable_error = 10**(-1-i)\n",
    "    root, iterations = bisection_method(example_polynomial,init_lower, init_upper, target_value, acceptable_error)\n",
    "    if abs(example_polynomial(root) - target_value) < acceptable_error:\n",
    "        print(f\"Error less than 10^({-1-i}) achieved in {iterations} steps\")\n",
    "    else:\n",
    "        print(f\"Method failed to converge in {max_iterations} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In typical markets, implied volatilities are rarely much larger than 100% per month, and are always non negative. One could therefore use initial lower and upper bounds of, for instance, 0 and 1000% for the bisection method, and have a reliable (but rather slow) way to compute implied volatilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 - The Newton-Raphson method\n",
    "\n",
    "This method is slightly more mathematically involved than the bisection method, and each step takes a bit longer to compute. However, it should (under the right conditions) converge much faster than the bisection method, and overall get a good estimate of the root more quickly. \n",
    "\n",
    "Given a point $x_i$, the method uses both the functions value and it's gradient at that point to determine a good next point $x_{i+1}$. More specifically, $x_{i+1}$ is given by:\n",
    "\n",
    "$$x_{i+1} = x_i - \\frac{f(x_i)}{f'(x_i)}$$\n",
    "\n",
    "Then we have that (under the right conditions) $x_n \\to y$ where $y$ is such that $f(y) = 0$.\n",
    "\n",
    "To use this, we of course need to be able to quickly compute the derivative (or some estimate of it) at a point. In exercise 1 we computed the derivative of the B.S. price with respect to volatility, so we know what this function is exactly and so can use the method.\n",
    "\n",
    "#### Derivation of the Newton-Raphson method:\n",
    "\n",
    "Exercise 7: Assume that our function $f$ satisfies $f(x)= ax+b$ for some unknown $a$ and $b$. If we are given the values of $f(x)$ and $f'(x)$, find $y$, the unique value such that $f(y) = 0$. (Your result should look similar to the Newton Raphson formula).\n",
    "\n",
    "#### Implementing the Newton-Raphson method:\n",
    "Now, we implement the Newton-Raphson method in code so we can use it for finding roots. We will make a version where one can implement a target value $V$ that it tries to solve for, so we aim to find a sequence of points $x_1, x_2,...$ with $x_n \\to y$ where $f(y) = V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(FUN, deriv_FUN, init_point, target_value, tol, max_iterations=250):\n",
    "    current_point = init_point\n",
    "    counter = 0\n",
    "    function_val = FUN(current_point) - target_value\n",
    "    while counter < max_iterations and abs(function_val) > tol:\n",
    "        function_val = FUN(current_point) - target_value\n",
    "        deriv_val = deriv_FUN(current_point)\n",
    "        current_point = current_point - function_val / deriv_val\n",
    "        counter +=1\n",
    "    return(current_point, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the same test as we did for the bisection method. As this method has more computations, we hope that it converges in fewer steps (and so overall runs faster). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_poly_derivative(x):\n",
    "    return(500*x**4 - 12*x**2 +1)\n",
    "\n",
    "\n",
    "init_point = 100\n",
    "target_value = 13.49546\n",
    "max_iterations = 35\n",
    "# With these values, the method should converge in <30 steps for each value of i.\n",
    "for i in range(8):\n",
    "    acceptable_error = 10**(-1-i)\n",
    "    root, iterations = newton_raphson(example_polynomial,example_poly_derivative,init_point, target_value, acceptable_error)\n",
    "    if abs(example_polynomial(root) - target_value) < acceptable_error:\n",
    "        print(f\"Error less than 10^({-1-i}) achieved in {iterations} steps\")\n",
    "    else:\n",
    "        print(f\"Method failed to converge in {max_iterations} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we see that to get within 10^(-1) took 26 steps, but it only took two more steps to get to less than 10^(-8). This demonstrates one of the key properties of the Newton Raphson method; When started from a point far from the correct root:\n",
    "- It may move towards the root slowly, taking much longer to get near the true value than other solutions.\n",
    "- It may oscillate between over and under estimating the root for a long period of time.\n",
    "- Even worse, these oscillations may even get larger with each iteration, with x_n shooting off to +- infinity.\n",
    "\n",
    "However, if the method is initialized near the correct value it can converge very quickly, with the number of correct digits in the decimal expansion of $x_n$ roughly doubling at each step. Thus, one common way to use NR is to get a relatively accurate guess of where the root(s) are and then apply NR one or two times to reduce the error to whatever level is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 - Drawbacks of the Netwton-Raphson method for Black Scholes prices:\n",
    "Now we look at some of the drawbacks of the NR method that are relevant to Black-Scholes prices:\n",
    "- We can only compute numerical estimates of the Black-Scholes price, and these rely on $\\Phi$. SciPy's normal CDF is only so accurate, as can be seen by the fact that norm.cdf(10) == norm.cdf(9) evaluates to TRUE, i.e. it cannot distinguish these from one another. For this reason, one generally tries to avoid computing implied volatilities with large $d_1$ values (i.e. deeply in the money options). Instead, one can compute the implied volatility mostly with near the money or out of the money options, where $d_1$ is smaller / negative. norm.cdf(-10) != norm.cdf(-9), so we still have some precision when evaluating the function here.\n",
    "- The Black-Scholes price, when considered only as a function of $\\sigma$, is concave for small $\\sigma$ and convex for large $\\sigma$. This is problematic because our estimates can overshoot the true value (sometimes by large amounts) and lead to it taking lots of steps to converge or to it diverging completely. We will illustrate this problem with the NR method by applying it to another function.\n",
    "- Even when the method does converge, it can take many iterations to get \"near\" the root before it starts to converge quickly (so it would help to have some sensible initial guess).\n",
    "\n",
    "We will now illustrate the second of these drawbacks on the function $f(x) = tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x}+e^{-x}}$. To do so, we will use a way to plot the iterations of the Newton Raphson method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By definition\n",
    "def tanh(x):\n",
    "    e_to_pos_x = np.exp(x)\n",
    "    e_to_neg_x = np.exp(-x)\n",
    "    numerator = e_to_pos_x-e_to_neg_x\n",
    "    denominator = e_to_pos_x+e_to_neg_x\n",
    "    return numerator/denominator\n",
    "\n",
    "# Can show by some fairly trivial algebra\n",
    "def deriv_tanh(x):\n",
    "    e_to_pos_x = np.exp(x)\n",
    "    e_to_neg_x = np.exp(-x)\n",
    "    numerator = 4\n",
    "    denominator = (e_to_pos_x+e_to_neg_x)**2\n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "# The true root (for a target value of 0) is 0. To show the behaviour, we start with a point a bit larger than 1\n",
    "init_point = 1.15\n",
    "iterations = 3\n",
    "\n",
    "# Running the NR method and saving the points:\n",
    "current_point = init_point\n",
    "iterates = [init_point]*(iterations+1)\n",
    "for i in range(iterations):\n",
    "    function_val = tanh(current_point)\n",
    "    deriv_val = deriv_tanh(current_point)\n",
    "    current_point = current_point - function_val / deriv_val\n",
    "    iterates[i+1] = current_point\n",
    "print(iterates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting iterates of the NR method:\n",
    "x_range = 20\n",
    "x_vals = np.linspace(-x_range,x_range, 500)\n",
    "tanh_vals = tanh(x_vals)\n",
    "NR_plot_function_curve = [go.Scatter(x=x_vals, y=tanh_vals, line = dict(color=\"red\"), name=\"tanh(x)\")]\n",
    "layout_NR_plot=  go.Layout(title = go.layout.Title(text=\"Newton Raphson applied to tanh(x)\"), \n",
    "                           xaxis = {\"title\": \"x\", \"range\":[-x_range,x_range]})\n",
    "\n",
    "# Some code to generate the iterates plots, showing the tangent lines\n",
    "NR_plot_tangents = [\n",
    "    go.Scatter(x=[iterates[i],iterates[i+1]], \n",
    "               y=[tanh(iterates[i]),0], \n",
    "               line=dict(color=\"blue\"), \n",
    "               name=\"Tangent\",\n",
    "               legendgroup=\"Tangent\",\n",
    "               showlegend=(i==0))  # Only show on legend once\n",
    "    for i in range(iterations)\n",
    "]\n",
    "\n",
    "# Code to generate the vertical lines\n",
    "NR_plot_function_evaluations = [\n",
    "    go.Scatter(x=[iterates[i],iterates[i]],\n",
    "               y=[0,tanh(iterates[i])],\n",
    "               line=dict(color=\"green\"),\n",
    "               name=\"Function evaluations\",\n",
    "               legendgroup = \"Function evaluations\",\n",
    "               showlegend = (i==0))\n",
    "    for i in range(iterations+1)\n",
    "]\n",
    "\n",
    "NR_plot_x_axis = [go.Scatter(x=[-x_range-5, x_range+5], y=[0,0], line = dict(color = \"black\"),showlegend=False)]\n",
    "\n",
    "NR_plot_objects = NR_plot_tangents + NR_plot_function_evaluations + NR_plot_function_curve + NR_plot_x_axis\n",
    "go.Figure(data=NR_plot_objects,layout = layout_NR_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, one can see that for our starting value of 1.15, the fact the function is convex for x less than the root and concave for x greater than the root mean that, when we start far from x, our estimates overshoot. Furthermore, they overshoot and increase in magnitude (from 1.15 to -1.318 to 2.156 et cetera). The next step after -16.499 is at x = 53,536,908,600,954 (53 trillion) which is extremely far from the root. \n",
    "\n",
    "The shape of the Black-Scholes price is somewhat similar to this function, but perhaps slightly better behaved as it's less common for errors to grow over time. Still, in some cases if the initial guess is far too low, it overshoots to extremely large values and takes a while to converge, or reaches a negative value (which is clearly incorrect as the volatility is non negative). \n",
    "\n",
    "One way to handle this is to use a hybrid of the bisection method and the Newton-Raphson method. The basic idea is to start with some (possibly quite large) interval containing the root, then to compute the next point of the NR method from the current best estimate (initially the midpoint, but if NR performs well then the previous NR iterate). If this next point is outside of the interval (i.e. Newton-Raphson overshoots) or is otherwise not converging quickly enough, it uses the bisection method. If not, it splits the region based on whether the next point of the NR method is positive or negative (above or below the root). This guarantees convergence and takes advantage of the fast convergence. An excellent book on [Numerical Recipes in C](https://www.grad.hr/nastava/gs/prg/NumericalRecipesinC.pdf) contains C code for this algorithm. (Newton Raphson is in section 9.4, starting on page 362). This hybrid approach is similar to the more common Brent's method, which we will now discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 - Brent's Method\n",
    "Brent's method also uses a hybrid of bisection and other algorithms, however instead of using Newton Raphson it uses a combination of:\n",
    "- The bisection method\n",
    "- The secant method\n",
    "- Inverse quadratic interpolation - This converges slightly faster than the secant method when near the root but can have poor initial performance, and when certain values coincide it can't be computed at all. We only use it when it can be computed.\n",
    "\n",
    "The main benefit of Brent's algorithm over the hybrid NR method is that it does not require the derivative. For our purposes, we have a derivative (and it's fast to compute) so this isn't much of a benefit. In fact, for determining implied volatilities the previous method will likely be slightly faster than Brent's method on average. However, Brent's method is much more widely applicable. For pricing more exotic options there is no closed form expression for the derivative so Brent's method is more widely used. Furthermore, Brent's method can be used for finding roots of other functions where the derivative is costly to compute and so it is likely to be more useful in other root finding problems you encounter.\n",
    "\n",
    "#### The secant method\n",
    "\n",
    "This method is very similar to the Newton-Raphson method covered above, however instead of dividing by the derivative we divide by an approximation to it. More specifically we use\n",
    "\n",
    "$$x_n = x_{n-1} - f(x_{n-1}) * \\frac{x_{n-1}-x_{n-2}}{f(x_{n-1}) - f(x_{n-2})}$$\n",
    "\n",
    "So we're replacing the $f'(x_{n-1})$ with the finite difference approximation $\\frac{f(x_{n-1}) - f(x_{n-2})}{x_{n-1}-x_{n-2}}$. \n",
    "\n",
    "This method has a slightly worse convergence than Newton Raphson as we're approximating the derivative, but when it is costly to evaluate the derivative it can do each step much more quickly leading to better overall convergence. Furthermore, one can save the past values of $f(x_{n-1})$, $f(x_{n-2})$ to use for future steps so after the first initial step only a single evaluation of $f(x_{n-1})$ is needed to get $x_n$ from $x_{n-1}$. \n",
    "\n",
    "The order of convergence when near the root is around 1.618, meaning approximately 1.6 times more digits are accurate at each step. This is worse than the Newton-Raphson method's 2, but still a fairly good convergence rate.\n",
    "\n",
    "#### Inverse quadratic interpolation\n",
    "\n",
    "This method builds on the secant method, trying to improve the convergence rates by using more past function values and iterates. It uses quadtratic interpolation to fit a quadratic that approximates $f^{-1}(y)$. One can substitute in the value $y=0$ and rearrange to get the recurrence relation:\n",
    "\n",
    "$$ x_{n+1} = \\frac{f(x_{n-1}) f(x_n)}{(f(x_{n-2})-f(x_{n-1}))(f(x_{n-2})-f(x_{n}))}x_{n-2} + \\frac{f(x_{n-2}) f(x_n)}{(f(x_{n-1})-f(x_{n-2}))(f(x_{n-1})-f(x_{n}))}x_{n-1} $$\n",
    "$$+\\frac{f(x_{n-2}) f(x_{n-1})}{(f(x_{n})-f(x_{n-2}))(f(x_{n})-f(x_{n-1}))}x_{n}$$\n",
    "\n",
    "However, if $f(x_{n-1}) \\approx f(x_{n-2})$ we can clearly see both of the first two terms become very large, and when $f(x_{n-1}) = f(x_{n-2})$ we cannot evaluate them. More generally we run into issues whenever $f(x_{n-2}), f(x_{n-1}), f(x_n)$ are not distinct. Like the secant method, we can save past values to reduce the amount of $f(x)$ calls the function uses and speed up computations significantly.\n",
    "\n",
    "The order of convergence for this method when near the root is around 1.84 (so a bit better than the secant method but worse than NR). \n",
    "\n",
    "Because of it's poor behaviour when $f(x_{n-2}), f(x_{n-1}), f(x_n)$ are not distinct, or are close to one another, inverse quadratic interpolation is rarely used. It's main use is in Brent's method because when the estimates are inaccurate it swaps to the bisection method instead of failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudocode for Brent's method\n",
    "\n",
    "The full method is as follows:\n",
    "\n",
    "    Take as inputs: points a and b, and a function f (defined between a and b)\n",
    "    if f(a) has the same sign as f(b) we exit with an error, as the method is only intended for situations where the root is between a and b.\n",
    "    Take (by swapping a and b) b to be the boundary of the interval s.t. |f(b)| <= |f(a)|. \n",
    "    Let b_prev be equal to a.\n",
    "    Let bisection_flag = TRUE\n",
    "    Let s = b\n",
    "    While f(s) is not near 0 and |b-a| is large:\n",
    "        if one can use inverse quadratic interpolation (i.e. $f(x_{n-2}), f(x_{n-1}), f(x_n)$ are distinct):\n",
    "            Let s = estimate from inverse quadratic interpolation\n",
    "        else:\n",
    "            Let s = estimate from secant method\n",
    "        end if\n",
    "        if (conditions(s,a,b,b_prev,b_2_prev,delta)):\n",
    "            Let bisection_flag = TRYE\n",
    "            Let s = a+b/2 \n",
    "        else:\n",
    "            Let bisection_flag = FALSE\n",
    "        end if\n",
    "        Let f_s = f(s)\n",
    "        Let b_2_prev = b_prev\n",
    "        Let b_prev = b\n",
    "        determine whether the root is between a and s or between s and b, then move a / b so the new interval has one boundary s and contains the root.\n",
    "        Take (by swapping a and b) b to be the boundary of the interval s.t. |f(b)| <= |f(a)|.  \n",
    "    end While\n",
    "    output s\n",
    "\n",
    "#### Conditions to use the interpolation method\n",
    "Where conditions(s,a,b,b_prev,b_2_prev,bisection_flag, delta) is a function returning a boolean for whether we should use the bisection method or secant/inverse quadratic interpolation. It's purpose is to ensure that the bisection method is used when the secant / inverse quadratic interpolation methods are performing poorly. As these can perform poorly in several different ways (overshooting, undershooting and taking too long to converge) there are several different conditions and if any of them are met Brent's method uses bisection instead of interpolation to avoid the poor behaviour. The full list is:\n",
    "- If the previous step used the bisection method:\n",
    "    - If $|b - b_{prev}| <$ delta (a small positive value), use bisection. This is to ensure that the interpolation method isn't undershooting and converging extremely slowly.\n",
    "    - If $|s - b| > 1/2 * |b-b_{prev}|$, use bisection. This is to ensure the new guess is no worse than the halving of the interval we would observe with the bisection method.\n",
    "- If the previous step used an interpolation method:\n",
    "    - If $|b_{prev}- b_{2\\_ prev}| <$ delta, use bisection. This is to ensure that the interpolation method isn't undershooting and converging extremely slowly.\n",
    "    - If $|s - b| > 1/2 * |b_{prev} - b_{2\\_ prev}|$, use bisection. This is to ensure the new guess is no worse than the halving of the interval we would observe with the bisection method.\n",
    "- Lastly, if $s$ does not lie between $(3a + b)/4$ and $b$, use bisection. Clearly, if $s$ is on the other side of $b$ to the interval, then $b$ must be closer to the root, and the bisection method should be used instead of the interpolation method. The other side, $(3a + b)/4$, is similar, and this particular weighted average of $a$ and $b$ is used because it reduces the analytical maximum number of steps in the worst case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brent's method implementation:\n",
    "def conditions(s,a,b,b_prev,b_2_prev,bisect_flag, delta):\n",
    "    if bisect_flag:\n",
    "        if abs(b-b_prev) < delta:\n",
    "            return True\n",
    "        if abs(s-b) > 0.5 * abs(b - b_prev):\n",
    "            return True\n",
    "    else:\n",
    "        if abs(b_prev - b_2_prev) < delta:\n",
    "            return True\n",
    "        if abs(s-b) > 0.5 * abs(b_prev - b_2_prev):\n",
    "            return True\n",
    "    \n",
    "    # If s is not between (3a+b)/4 and b, both of the terms must be positive / both negative. \n",
    "    # Hence the product must be positive.\n",
    "    if (s-b) * (s-(3*a + b)/4) >= 0: \n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brent's method in code\n",
    "Exercise 8: Using the conditions function above, complete the following code for Brent's method. Consider carefully what should happen when\n",
    "    \n",
    "    abs(f_b) < tol_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant_method(a,b, f_a, f_b):\n",
    "    return b - f_b* (b-a)/(f_b-f_a)\n",
    "\n",
    "def inverse_quadratic_interp(a,b,c,f_a,f_b,f_c):\n",
    "    term_1 = a * f_b * f_c / ((f_a - f_b)*(f_a - f_c))\n",
    "    term_2 = b * f_a * f_c / ((f_b - f_a)*(f_b - f_c))\n",
    "    term_3 = c * f_a * f_b / ((f_c - f_a)*(f_c - f_b))\n",
    "    s = term_1 + term_2 + term_3\n",
    "    return s\n",
    "\n",
    "def swap(a,b):\n",
    "    return b,a\n",
    "\n",
    "def brent_method(FUN, a, b, target_value, tol_height, tol_width, delta=0.001):\n",
    "    def f(x):\n",
    "        return FUN(x) - target_value\n",
    "    # Save values to avoid calling f multiple times, speeding up computation\n",
    "    f_a = f(a)\n",
    "    f_b = f(b)\n",
    "    if f_a*f_b >= 0:\n",
    "        return f\"Error: No change of sign between {a} and {b}, can't perform method.\"\n",
    "    if abs(f_a) < abs(f_b):\n",
    "        # swapping a and b, f_a and f_b\n",
    "        a,b = swap(a,b)\n",
    "        f_a, f_b = swap(f_a, f_b)\n",
    "    b_prev = a\n",
    "    b_2_prev = 0\n",
    "    f_b_prev = f_a\n",
    "    bisect_flag = True\n",
    "    s= np.array([b])\n",
    "    # Exercise 8 starts here\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the method, we'll showcase it's performance on finding the root of a function we know to be tricky, tanh, using some initial values that would certainly cause issues for a more basic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = brent_method(tanh, a=-50, b=100, target_value = 0, tol_height = 0.0001, tol_width = 0.0001, delta = 0.001)\n",
    "\n",
    "# Our root is near 0:\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the brent method still converges despite the poor behaviour we would expect from the tanh function, even when we start from $[-50,100]$, an interval we know leads to overshooting with NR / the secant method. Brent's method, and the hybrid bisection / NR method, are both used for computing implied volatilities fairly commonly as they are often quick enough for most purposes. There are, however, much faster methods (see Extensions) that take advantage of features specific to the shape Black-Scholes price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Plotting the Volatility Surface\n",
    "Now that we have:\n",
    "- A way to obtain options chain data\n",
    "- Implemented a function for the Black-Scholes price \n",
    "- Coded a fast method to compute roots of functions\n",
    "\n",
    "We will now combine these to get a set of implied volatilities and then use these to produce a volatility surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"META\"\n",
    "ticker_options_df = get_options_data(ticker)\n",
    "# For the current prices, we will use the midpoint of the bid and ask (one could try many other things here)\n",
    "\n",
    "midpoint = 0.5 * (ticker_options_df[\"bid\"] + ticker_options_df[\"ask\"])\n",
    "\n",
    "# In some cases, yfinance has no data for the bid and ask prices. It often returns 0s here instead of saying that it doesn't have any data.\n",
    "# To avoid this, we'll set the price to be the midpoint when bid and ask prices exist, and the most recent price otherwise.\n",
    "\n",
    "prices = [x if x != 0 else y for x,y in zip(midpoint, ticker_options_df[\"lastPrice\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_options_df[\"Average_price\"] = prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_ticker = yf.Ticker(ticker)\n",
    "yf_ticker_data = yf_ticker.history()\n",
    "last_quoted_price = yf_ticker_data[\"Close\"].iloc[-1] # gets the last close data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lower = 0.01\n",
    "init_upper = 10000\n",
    "\n",
    "# Fixing the risk free rate as the current US Treasury Bill yield.\n",
    "risk_free = 0.049\n",
    "\n",
    "# Defining the Brent method for the Black-Scholes price. We want it to work for both call and put options.\n",
    "def BS_brent_method(time_to_expiry, strike_price, current_price, risk_free, a, b, target_value, tol_height, tol_width, call):\n",
    "    if target_value == 0:\n",
    "        return(\"Error: price is 0\")\n",
    "    if call:\n",
    "        def FUN(x):\n",
    "            return black_scholes_call_price(x,time_to_expiry, strike_price, current_price, risk_free)\n",
    "    else:\n",
    "        def FUN(x):\n",
    "            return black_scholes_put_price(x,time_to_expiry, strike_price, current_price, risk_free)\n",
    "    return brent_method(FUN, a,b,target_value, tol_height, tol_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One quick point to note: We're computing the time to expiry in days, and it's rounded to the nearest day. When the code runs during market hours, some options may expire later that day, and so have 0 days until expiry. A quick glance at the Black-Scholes prices shows that $T-t$ being equal to 0 will lead to errors. To fix this we will simply ignore 0DTE options, but one could also compute the days to expiry as a float with the exact time left and use that value instead of filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instance, here we'll get errors when we try to use 0 as the time to expiration.\n",
    "low_vol_price = black_scholes_call_price(0.01,0, 100, last_quoted_price, risk_free)\n",
    "high_vol_price = black_scholes_call_price(100000,0, 100, last_quoted_price, risk_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_options_df = ticker_options_df[ticker_options_df[\"DTE\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_prices = filtered_options_df[[\"Average_price\"]].to_numpy()\n",
    "strikes = filtered_options_df[[\"strike\"]].to_numpy()\n",
    "DTEs = filtered_options_df[[\"DTE\"]].to_numpy()\n",
    "yfin_IVs = filtered_options_df[[\"impliedVolatility\"]].to_numpy()\n",
    "calls = filtered_options_df[[\"call\"]].to_numpy()\n",
    "\n",
    "IVs = [BS_brent_method(days_to_expiry/365, strike_price, last_quoted_price,risk_free, \n",
    "                       init_lower, init_upper, option_price, tol_height=0.0001, tol_width=0.0001, call= call)\n",
    "                       for days_to_expiry, strike_price, option_price, call in zip(DTEs, strikes, option_prices, calls)]\n",
    "# Note: For assets with many options, this can take a few seconds - a few minutes to compute.\n",
    "# (seconds for stocks with relatively few options, minutes for those with many options - i.e. Nvidia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it takes longer than 5 minutes something has likely gone wrong with your implementation, or the yfinance data is erroneous. In these cases try a different less liquid ticker and see if it runs in a reasonable time. If not, look through your Brent method code and make sure it's working correctly. If neither of these fix it please ask about it on the GitHub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indices where we got valid implied volatilities (i.e. our initial interval contained a root):\n",
    "valid_indices = [not isinstance(iv, str) for iv in IVs]\n",
    "valid_IVs = [iv for iv in IVs if not isinstance(iv,str)]\n",
    "valid_IVs = np.squeeze(np.array(valid_IVs))\n",
    "valid_strikes = np.squeeze(strikes[valid_indices])\n",
    "valid_DTEs = np.squeeze(DTEs[valid_indices])\n",
    "valid_yfin_IVs = np.squeeze(yfin_IVs[valid_indices])\n",
    "valid_prices = np.squeeze(option_prices[valid_indices])\n",
    "\n",
    "# Saving these as a data frame for future use.\n",
    "valid_options = pd.DataFrame({\"strike\":valid_strikes,\n",
    "                              \"DTE\":valid_DTEs,\n",
    "                              \"IV\":valid_IVs, \n",
    "                              \"yfin_IV\":valid_yfin_IVs, \n",
    "                              \"price\": valid_prices})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we combine all of this into a single function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_surface_data(ticker, tol_height = 0.001, tol_width = 0.001):\n",
    "    ticker_options_df = get_options_data(ticker)\n",
    "    midpoint = 0.5 * (ticker_options_df[\"bid\"] + ticker_options_df[\"ask\"])\n",
    "    \n",
    "    # In some cases, yfinance has no data for the bid and ask prices. It often returns 0s here instead of saying that it doesn't have any data.\n",
    "    # To avoid this, we'll set the price to be the midpoint when bid and ask prices exist, and the most recent price otherwise.\n",
    "    prices = [x if x != 0 else y for x,y in zip(midpoint, ticker_options_df[\"lastPrice\"])]\n",
    "    ticker_options_df[\"Average_price\"] = prices\n",
    "\n",
    "    yf_ticker = yf.Ticker(ticker)\n",
    "    yf_ticker_data = yf_ticker.history()\n",
    "    last_quoted_price = yf_ticker_data[\"Close\"].iloc[-1] # gets the last close data.\n",
    "\n",
    "    init_lower = 0.001\n",
    "    init_upper = 100\n",
    "    ticker_options_df = ticker_options_df[ticker_options_df[\"DTE\"]!=0]\n",
    "    option_prices = ticker_options_df[[\"Average_price\"]].to_numpy()\n",
    "    strikes = ticker_options_df[[\"strike\"]].to_numpy()\n",
    "    DTEs = ticker_options_df[[\"DTE\"]].to_numpy()\n",
    "    yfin_IVs = ticker_options_df[[\"impliedVolatility\"]].to_numpy()\n",
    "    calls = ticker_options_df[[\"call\"]].to_numpy()\n",
    "    \n",
    "    IVs = [BS_brent_method(days_to_expiry/365, strike_price, last_quoted_price,risk_free, \n",
    "                       init_lower, init_upper, option_price, tol_height=tol_height, tol_width=tol_width, call= call)\n",
    "                       for days_to_expiry, strike_price, option_price, call in zip(DTEs, strikes, option_prices, calls)]\n",
    "    \n",
    "    valid_indices = [not isinstance(iv, str) for iv in IVs]\n",
    "    valid_IVs = [iv for iv in IVs if not isinstance(iv,str)]\n",
    "    valid_IVs = np.squeeze(np.array(valid_IVs))\n",
    "    valid_strikes = np.squeeze(strikes[valid_indices])\n",
    "    valid_DTEs = np.squeeze(DTEs[valid_indices])\n",
    "    valid_yfin_IVs = np.squeeze(yfin_IVs[valid_indices])\n",
    "    valid_prices = np.squeeze(option_prices[valid_indices])\n",
    "\n",
    "    valid_options = pd.DataFrame({\"strike\":valid_strikes,\n",
    "                              \"DTE\":valid_DTEs,\n",
    "                              \"IV\":valid_IVs, \n",
    "                              \"yfin_IV\":valid_yfin_IVs, \n",
    "                              \"price\": valid_prices})\n",
    "    return(valid_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data as a csv for future reference (Optional)\n",
    "We can use the standard python package os, (documentation here: https://docs.python.org/3/library/os.html) to get the current file path. Alternatively, put in wherever you'd like to save them. If you're not running this Jupyter Notebook locally, skip this step / use whatever method to save / access files that system uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ticker = \"SHEL\"\n",
    "valid_options = get_vol_surface_data(ticker)\n",
    "\n",
    "# Gets the current working directory\n",
    "file_path = os.path.abspath(\"\")\n",
    "\n",
    "# A name for the file we're saving:\n",
    "file_name = f\"//{ticker}_data_on_{datetime.datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "\n",
    "# Saving the file as a csv:\n",
    "valid_options.to_csv(file_path+file_name)\n",
    "\n",
    "# Can then read the data with something like the following (You can find this specific file on the Github):\n",
    "# load_ticker_name = \"AAPL\"\n",
    "\n",
    "# old_file_name = f\"\\\\{load_ticker_name}_data_on_2024-07-26.csv\"\n",
    "# valid_options = pd.read_csv(file_path+old_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Check this against the plot when using valid_yfin_IVs as z, to see visually how our method compares.\n",
    "scatterobj = go.Scatter3d( z = valid_options[\"IV\"], x= valid_options[\"strike\"], y= valid_options[\"DTE\"], mode=\"markers\",\n",
    "                          marker=dict(\n",
    "                              color= valid_options[\"IV\"],\n",
    "                              colorscale= \"Viridis\",\n",
    "                              size=5,\n",
    "                          ))\n",
    "fig = go.Figure(data = [scatterobj])\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Arbitrage in volatility surfaces\n",
    "### 5.1.1 - Refresher on arbitrage\n",
    "As an arbitrage is a trade or set of trades that, when one performs them:\n",
    "- Will never lose money\n",
    "- Will sometimes gain money\n",
    "\n",
    "General financial theory is that if these opportunities exist, someone would notice them and perform the trades, locking in guaranteed profits. This would then cause the prices to move and the opportunitiy to disappear. Therefore, when one is operating on longer time scales it is reasonable to assume that they won't see arbitrage opportunities often, so we should expect our volatility surfaces to not contain arbitrage. Another context where volatility surfaces are relevant is when options market makers need to determine fair prices for them. In this case it is also important to not have arbitrage in the surfaces as if so, another trader can exploit it and make profits off of the market maker. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 - Arbitrage types for for volatility surfaces\n",
    "In this plot, we see the first signs of the volatility surface. One possible approach would be to linearly interpolate across the gaps to form a full surface. This method, however, is likely to be suboptimal because it is likely to lead to arbitrage opportunities. There are two main types of arbitrage opportunities in the context of volatility surfaces:\n",
    "- Calendar spread arbitrage - Buying a call and selling a call (alternatively buying a put and selling a put) with the exact same strike price but different times to expiry. If the volatility surface is constructed without care, this trading strategy will always be profitable. If we were an options market maker and were used this surface to price other options, then another market participant could make guaranteed profit off of us. \n",
    "- Butterfly arbitrage - These apply to individual slices of the volatility surface (sets of options with the same maturity). When a butterfly arbitrage exists, there is some time to expiry and set of strikes such that one can buy and sell different options expiring at that time and produce a guaranteed profit.\n",
    "\n",
    "We'll now do some exercises to illustrate these types of arbitrage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 - Calendar spread example\n",
    "Exercise 9: Let $C(T,K)$ be the price of a call option (assume the other parameters are the same for both options). Fix $K$ and let $0 < T_1 < T_2$. If $C(T_1, K_1) > C(T_2, K_2)$, where $K_2 = K_1 e^{r(T_2 - T_1)}$ find an arbitrage opportunity and show it is an arbitrage (i.e. that you'll never lose money when employing it, and will sometimes profit). It may be helpful for the strategy to buy/sell the underlying as well as the options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 - Butterfly arbitrage\n",
    "\n",
    "Exercise 10a:\n",
    "\n",
    "Consider two call options each with the same expiry $T$ and with strikes $90,100$. Say that these are the only assets we can invest in (so we cannot buy or sell the underlying). Let (x,y) be the number of units of the options with strikes (90,100) respectively. If they have positive prices $20,d$ respectively, then under what conditions on $d$ is there an arbitrage opportunity?\n",
    "How should one trade to profit off of the opportunity?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 10b:\n",
    "\n",
    "Now say a new option with the same expiry, strike $110$ and price $10$ is released. Let the number of units of options with strikes $(90,100,110)$ be $(x,y,z)$. Show that $d=16$ would now also lead to an arbitrage opportunity (Hint: consider $(x,y,z) = (1,-2,1)$)\n",
    "\n",
    "If you want an extra challenge: Is this portfolio unique up to scalar multiplication?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Interpolating on volatility surfaces\n",
    "\n",
    "A large part of modern research is on finding methods to interpolate / fit models to a set of implied volatilities in a way that doesn't create arbitrage opportunities and has low errors. It is difficult to include the conditions of convexity and of not allowing calendar arbitrage (One can perform a change of variables and express the terms involved in the volatility surface as other variables. In these, no calendar arbitrage is equivalent to one of the variables increasing with respect to another). Because of these difficulties in specifying interpolation methods, a common idea is to have a parameterized model which, for any combination of parameter values, guarantees no arbitrage. One can then fit this model (by, for instance, minimising the RMSE). \n",
    "\n",
    "A basic model that aims to fit parameters to our implied volatilities is the SVI model (see: [Arbitrage free SVI Volatility Surfaces](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323)) which was originally devised at Merrill Lynch in 1999. The idea behind this model is to (roughly) fit the observed option prices, but to also ensure that no arbitrage opportunities exist on the resulting surface. A proper understanding of this model, and how to fit it, requires a good understanding of stochastic calculus, and is included as an optional extension exercise. To highlight how difficult it is to ensure a volatility surface has no arbitrage, the original SVI model actually can have arbitrage opportunities (and even ones for realistic data - see: [Arbitrage Free Implied Volatility Surfaces\n",
    "](https://talus.maths.usyd.edu.au/u/pubs/publist/preprints/2010/roper-9.pdf), page 20-21). There are some extensions / modifications to the SVI model that do ensure it remains arbitrage free (see the extension section of the references).\n",
    "\n",
    "We will instead cover some simpler more standard ways to interpolate over missing values. There are many methods, and we will cover two fairly simple ones to give a taste of the ideas:\n",
    "- Linear interpolation - This method applies linear interpolation horizontally, then vertically, between points in our region. It generally performs poorly for volatility surfaces as it can (quite commonly) lead to a surface including calendar arbitrage.\n",
    "- Cubic spline interpolation - This method estimates a smooth cubic curve that goes through every point. It is widely used for volatility surface interpolation. Unfortunately, this method may also not be arbitrage free as it doesn't preserve the convexity of option prices.It is also outperformed by other more modern methods that are both faster to compute and more accurate.\n",
    "\n",
    "There are many methods to interpolate some points into a surface. Kriging is another interpolation method that has been suggested as another reasonable approach, and one can even use it while guaranteeing the resultant surface satisfies no arbitrage conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 - Linear interpolation\n",
    "There are several ways one can interpolate \"linearly\". One method is to compute (using some other method, possibly also interpolation) implied volatility along a line of fixed time to expiry, then to perform linear interpolation between the slices. One can show (for instance in [this paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2175001) by Fabien Le Floc'h) that linear interpolation is not guaranteed to avoid an arbitrage, which is one reason why it may be unwise to use linear interpolations between slices. We aren't going to use exactly this approach, but it is entirely possible that our method will lead to a volatility surface containing an arbitrage for similar reasons. \n",
    "\n",
    "One linear interpolation method is bilinear interpolation, where one applies a linear interpolation vertically to form lines covering the region, then horizontally to cover the full region. If we have values that are not regularly spaced in a grid it's not clear how one should extend this, (although there are some packages that allow for irregular grids. One such pckage in R is akima which is based on [this paper](https://dl.acm.org/doi/10.1145/355780.355786) by Hiroshi Akima). In Python, SciPy has several \"linear\" interpolation functions that can be used on irregular grids which we will make use of. One can see the benefits of a function that works for irregular grids by looking at the set of options we have information for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = go.Scatter(x=valid_options[\"strike\"], y=valid_options[\"DTE\"], mode=\"markers\"))\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like in this case (where we only look at the options for which our implied volatility computations converged) that if we were to use a grid we would only be able to use a small portion of our data (Hence the need for irregular grids). The function we consider for linear interpolation is SciPy's LinearNDInterpolator. This creates a mesh of triangles (called a Delaunay triangulation) from points in our data such that:\n",
    "- Every triangle has vertices 3 data points\n",
    "- Triangles cover the full convex hull of our data (meaning that if we draw any straight line between two data points, each point on the line is in a triangle)\n",
    "- No triangles contain another data point\n",
    "\n",
    "Note: Delaunay triangulation actually gives even stronger results than this. See the reference on Delaunay triangulation for a more detailed explanation. \n",
    "\n",
    "As a brief aside, we will show the idea behind Delaunay triangulation visually. Play around with the points included and see how the result changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Play around with adding or taking away points to see how the resulting plot changes:\n",
    "points = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0.1,2],[1,1],[1.5,2],[1.3,1],[4,5],[3,4],[3,1],[0.6,3.5], [3.5,0], [1,0],[2.4,0],[0.7,4.3]])\n",
    "# points = np.array([[0, 0], [0, 1.1], [1, 0], [1, 1]])\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "# Computing the triangles (Delaunay triangulation of our data)\n",
    "tri = Delaunay(points)\n",
    "\n",
    "# Plotting our points\n",
    "plt.plot(points[:,0], points[:,1], 'o')\n",
    "\n",
    "# Plotting our triangles\n",
    "plt.triplot(points[:,0], points[:,1], tri.simplices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, to interpolate a given point in our grid LinearNDInterpolator:\n",
    "- Determines which triangle it is in, say it's in the triangle with vertices $v_1,v_2,v_3$.\n",
    "- Writes the point's position as $a_1 v_1 + a_2 v_2 + a_3 v_3$ where $a_i>0$ for all $i$ and $\\sum_i a_i = 1$.\n",
    "- Gives an interpolated value of $\\sum_i a_i f(v_i)$. (In our case the weighted sum of the implied volatilities of the 3 vertex points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by strike then by DTE to order our values\n",
    "valid_options.sort_values(by=[\"strike\",\"DTE\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pass our data (in the correct format) into SciPys LinearNDInterpolator\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "plotted_options = valid_options.tail(-1) # Ignoring the first one as it's very large, and makes it difficult to see the other points.\n",
    "\n",
    "# Initialising our linear interpolator\n",
    "lin_interpolator = LinearNDInterpolator(list(zip(plotted_options[\"strike\"],plotted_options[\"DTE\"])), plotted_options[\"IV\"])\n",
    "\n",
    "# Making grid of points we'll evaluate our interpolation function on\n",
    "strike_vec = np.linspace(min(plotted_options[\"strike\"]), max(plotted_options[\"strike\"]))\n",
    "DTE_vec = np.linspace(min(plotted_options[\"DTE\"]), max(plotted_options[\"DTE\"]))\n",
    "\n",
    "X,Y = np.meshgrid(strike_vec,DTE_vec) # Standard function that forms a 2D grid from the linspaces we've just created\n",
    "\n",
    "# Using the linear interpolator to get values\n",
    "IV_vals = lin_interpolator(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [go.Surface(x=strike_vec, y=DTE_vec, z=IV_vals, colorscale = \"Blues\", surfacecolor=IV_vals)])\n",
    "fig.update_layout(title = f\"Linearly interpolated volatility surface for {ticker}\", autosize = False,\n",
    "                  width = 600, height= 600, \n",
    "                  margin = dict(l=50, r=50, t=90, b=50))\n",
    "fig.update_scenes(zaxis_title_text = \"Implied Volatility\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 - Cubic spline interpolation\n",
    "Next, one of the most common methods to interpolate over implied volatility surfaces. This results in (sometimes) slightly smoother plots, but similar to linear interpolation, it does not prevent arbitrage opportunities. We will use CloughTocher2DInterpolator which constructs a continuously differentiable piecewise cubic interpolator. Just like in LinearNDInterpolator, it first triangulates the data. Then, it uses piecewise cubic polynomials on each triangle (determined with a Clough Toucher scheme). Cubic functions are always continuously differentiable, but at the boundaries (edges of triangles) they may not be. The method forces points on these edges to also be continuously differentiable.\n",
    "\n",
    "The method tries to minimize curvature of the resulting surface (there are multiple ways to fit a cubic, and we take the one that's \"smoothest\" in the sense of minimal curvature). For a more thorough description, see the papers linked from [this SciPy page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.CloughTocher2DInterpolator.html). \n",
    "\n",
    "Exercise 11: Using the linear interpolation code above as a template, create the same plot but using CloughTocher for cubic spline interpolation instead of linear interpolation. Also:\n",
    "- Set colorscale to be \"RdBu\".\n",
    "- Flip the way colors are applied by changing the value surfacecolor is set to.\n",
    "- Add a title and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 - Aesthetic changes (Optional)\n",
    "This section has no real practical applications, but for those interested in making their volatility surfaces look prettier, we will discuss some modifications one can make to improve the look of the plotly plots. \n",
    "\n",
    "One can change the colour to look like the typical volatility surfaces you see on google using colorscale = \"Jet\" instead of \"RdBu\" or \"Blues\". Another commonly seen feature on volatility surfaces is a grid. We can include this in plotly fairly easily. \n",
    "\n",
    "Exercise 12: Oh no, there's a bug in the code. The lines are showing up in the wrong place. Figure out where the error is and correct it to fix the plot. (You may also want to add the axis labels and play around with the aesthetics here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the standard figure again\n",
    "fig = go.Figure(data = [go.Surface(x=strike_vec, y=DTE_vec, z=cubic_IV_vals, colorscale = \"Jet\", surfacecolor=cubic_IV_vals)])\n",
    "fig.update_layout(title = \"A volatility surface\", autosize = False,\n",
    "                  width = 600, height= 600, \n",
    "                  margin = dict(l=50, r=50, t=90, b=50))\n",
    "fig.update_scenes(zaxis_title_text = \"Implied Volatility\")\n",
    "\n",
    "# Exercise 12 starts here:\n",
    "\n",
    "# Creating a grid in an order that leads to lines parallel to the DTE axis instead of parallel to the strike axis:\n",
    "X_rev, Y_rev =np.meshgrid(DTE_vec, strike_vec)\n",
    "# Setting the parameters of the lines on our grid:\n",
    "line_marker = dict(color=\"black\",width=2)\n",
    "\n",
    "# Adding grid lines in one direction:\n",
    "for x,y,z in zip(X,Y,cubic_IV_vals):\n",
    "    fig.add_trace(go.Scatter3d(x=x,y=y,z=z, mode=\"lines\",line=line_marker, showlegend=False))\n",
    "\n",
    "# Adding grid lines in the other direction:\n",
    "for x,y,z in zip(X_rev, Y_rev, IV_vals.T):\n",
    "    fig.add_trace(go.Scatter3d(x=x,y=y,z=z, mode=\"lines\",line=line_marker, showlegend=False))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 - Other plotting considerations:\n",
    "We can see even from a brief look at the plots that these implied volatility surfaces are very rough. This isn't necessarly a problem, as the arbitrage conditions regarding convexity and monotonicity we've stated only apply to the prices. However, these very rough surfaces may be an indication that the prices this surface would give may have arbitrage opportunities (both butterfly arbitrage and calendar arbitrage seem to be present). Furthermore, this isn't an artefact of some inaccuracy in our IV computation as the same behaviour appears when using yfinance's computed IVs (you can quite easily modify the above to check this for yourself). \n",
    "\n",
    "All hope is not lost. There are many other things one may wish to consider when producing sensible volatility surface plots to lower the chances of arbitrage opportunities and inaccuracies even when using a method that doesn't guarantee an arbitrage-free surface. Some things to think about include:\n",
    "- Data quality in financial markets is imperfect and when data is missing we will sometimes get prices of 0 for the bid/ask/current price (which are clearly incorrect). This will wreak havoc on the model if they aren't checked and protected against. At the moment we default to the last traded price in these situations.\n",
    "- The recency of data can have a big impact. In some cases the most recent price is quite old and would no longer be a sensible price (i.e. the underlying has changed value significantly since then). Furthermore, sometimes options are traded on a market with different trading times to that of the underlying, which can lead to prices for one being more recent than the other and making our implied volatilities incorrect.\n",
    "- There are several options for which prices to use. One can use the bid, the ask, the midpoint of the bid and the ask and (for more liquid markets) the most recent price. One may also want to include information about the size of the spread as this is very important when considering arbitrage opportunities (even if a theoretical arbitrage may exist, if the spread is large it will not be profitable).\n",
    "- If one uses the midpoint (as we have) it is  possible for there to be no arbitrage in the real market but an arbitrage opportunity may appear to exist when one looks only at the midpoints. For this reason it can make sense to ignore prices where the spread is particularly large.\n",
    "- Similarly, out of date / incorrect option prices can lead to non monotonic prices as the strike/time to maturity changes (which is again quite problematic, as it also creates arbitrage opportunities)\n",
    "- Some exchanges (For instance ICE, EUREX) send settlement prices - the price at which trading the asset closes / was last traded for. If they haven't had a trade in a few days, they may still provide a settlement price which is far from the trading price of similar options and would lead to an arbitrage if included.\n",
    "- Using primarly out of the money options - If one uses in the money options, these have generally higher prices and larger spreads (making the bid vs midpoint vs ask vs most recent traded price choice much more impactful). We can see in some places our implied volatilities seem to be changing rapidly for different strike prices. One plausible reason for this is that some strike prices have call option data while others have puts, so when either the call or put prices are inaccurate, we get these poorly behaved oscillations.\n",
    "- Exercise 13: Give another reason (involving computing the implied volatilities from a \"correct\" stock price) for why we may wish to not consider deeply in the money options.\n",
    "\n",
    "One possible extension activity would be use the above ideas and explore filtering which options are used to make our volatility surfaces in order to improve our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Volatility Surface terms and properties\n",
    "Some specific slices of the volatility surface are important enough in trading to have their own names and many volatility strategies may use only one aspect to determine the profitability of trades. We will also discuss some typical types of volatility surfaces and some typical behaviours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 - Volatility Skew\n",
    "Volatility skew is the general term for the shape of the cross section of the volatility surface with a fixed time to expiry (strikes varying). Typically the words \"Volatility skew\" (also \"negative skew\" or \"reverse skew\") on their own refer to the case where we have higher implied volatilities for low strike prices than for high strike prices. The most common reason for this that investors are willing to pay a premium for put options to protect against large market crashes. Some trading strategies (including one that was in a coding session last year called VolatilityRiskPremium) involve selling these puts to take advantage of this premium as the strategies suppose that investors are overpaying out of fear of a big crash.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 - Positive / forward skew\n",
    "Another type of volatility skew is positive / forward skew. This, as you would expect, is the opposite of negative / reverse skew. Implied volatility for high strikes is higher than it is for low strikes. This suggests market participants are expecting a fairly sharp increase in prices, and are willing to pay a little bit extra to make a profit off of the increase. Positive skew is commonly found in commodities like gold and oil. One reason for this with gold and other \"safe haven\" assets is that in market crashes, people tend to buy gold and other precious metals. Oil, as well as other commodities that are needed to make other products, can have sudden demand surges where lots of people need them causing prices to rise suddenly which can also lead to positive skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 - Flat / no skew\n",
    "This refers to when the implied volatility is (roughly) the same across options. In these cases, investors expectations of future returns perfectly match the log-normal distribution that the Black-Scholes model predicts. This doessn't, however, mean that the volatility is similar to historical levels. Often changes in the overall height of the volatility surface can be as important as the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 - Volatility smiles\n",
    "One common shape for the volatility skew to take is a \"smile\", with higher implied volatilities further from the strike price and lower implied volatilities closer to the strike. There are several plausible explanations for volatility smiles, including:\n",
    "- Demand is higher for in / out of the money options than at (or near) the money ones, so they're more expensive and therefore have a higher implied volatility.\n",
    "- Market participants expect a higher probability of \"rare\" market events (i.e. future stock prices follow a platykurtic distribution, a one with thinner tails than a normal distribution). Many modern option pricing models predict the true chances of \"rare\" market events as higher than that of Black-Scholes. They therefore have different (larger) estimates of the changes of a massive increase / decrease in price than the Black-Scholes model predicts leading to higher implied volatilities. \n",
    "\n",
    "One piece of evidence supporting the \"market participants expect a higher probability of rare events\" hypothesis is that before the 1987 crash, volatility surfaces were much flatter. After 1987, market participants realised that these \"rare\" events were much more common than the Black-Scholes model would predict and implied volatilities far from the strike increased.\n",
    "\n",
    "Some research also suggests there is a relationship between how \"strong\" / curved the volatility smirk is and the future performance of the underlying. Also, if investors expect the underlying to perform poorly, they may buy OTM puts for downside protection (increasing the implied volatility for low strikes) and if they expect the underlying to perform well, they may buy OTM calls. Hence, the current volatility surface can give some indications of expected future performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 - Inverted volatility smiles\n",
    "In some (generally rarer) cases, implied volatility can be highest near the money and lower far from the money, leading to an \"inverted smile\" (or frown, but inverted smile is the more common term). There are some meaningful reasons for this:\n",
    "- Market participants expect a lower probability of \"rare\" market events (i.e. future stock prices follow a platykurtic distribution, a one with thinner tails than a normal distribution)\n",
    "- When a significant jump in stock price is likely to occur at a predictable time, inverted volatility smiles tend to occur. This is because the probability the stock being near its current price in the future is low, and it is more likely to be further from the current strike. Some real world examples of this include: \n",
    "    - When a pharmaceutical company has a drug that's about to finish the last clinical trial (if successful, the share price increases massively, if unsuccessful, the share price decreases massively)\n",
    "    - When a large tech company is about to release an earnings report (if the earnings are good the price will jump up, if poor it will fall rapidly)\n",
    "    - For large sectors of the market: when a large election (i.e. for the US president) is about to take place between candidates with very different views (i.e. one will bring harsh regulation and higher taxes, while the other promises deregulation and tax cuts)\n",
    "    - For large sectors of the market: When the Federal Open Market Committee is about to release the interest rate announcement for the coming months\n",
    "There are models devoted to determining sensible options prices prior to earnings announcements (and other big shifts of this nature). For instance [this paper](https://business.columbia.edu/sites/default/files-efs/pubfiles/6051/DJ_2006.pdf) discusses the improvements that can be made when one takes into account earnings announcements. \n",
    "\n",
    "More generally, jump diffusion models are used to get better prices for options both in cases of inverted volatility smiles and more generally. There are a range of different jump diffusion models and many involve too much stochastic calculus to be included here. For a more detailed review of jump diffusion models, see [this paper](https://www.columbia.edu/~sk75/MagSci02.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 - Volatility term structure\n",
    "This refers to how the implied volatility changes for different times to expiry with the same strike price. These can change based on lots of important information in the markets. For instance, the impact of a successful or failing drug trial can lead to higher implied volatility on options just after the trial than just before. Generally options expiring just after the event have a larger change in implied volatility than those expiring much later than the event. Several events can cause increases in implied volatility observable in the term structure including:\n",
    "- US Treasury bills have increased volatlity just before short-term interest rates are announced\n",
    "- Commodities like corn show increased volatility prior to the announcement of harvest forecasts\n",
    "\n",
    "Volatility term structures can more generally be:\n",
    "- increasing, so the market expects higher volatility far in the future than in the short term\n",
    "- decreasing, the market exprects lower volatility far in the future than in the short term\n",
    "\n",
    "In practice, the term structures are rarely truly monotonic, and whether a term structure is increasing or decreasing is determined by the general pattern. \n",
    "\n",
    "Some reasons for increasing volatility term structures include future supply disruptions (i.e. if there's an expectation of a large war in a couple months, and in this war one of the participants is a major oil exporter, the volatility of oil prices will be much higher in the future than tomorrow).\n",
    "\n",
    "Far in the future implied volatilities are generally fairly similar to historic volatilities. One possible reason behind this gradual return to a more \"normal\" lower volatility is said to be because a stock cannot have extremely high volatility for a long time, and must eventually revert to it's historical mean. Therefore, if the current short term implied volatility is particularly high then the long term volatility should be lower than the short term and we get a decreasing implied volatility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 - Volatility structuce in trading strategies\n",
    "\n",
    "The volatility term structure can be used to predict returns of stocks. For instance in [this paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1944298) a clear relationship is seen between the slope of the volatility term structure and future stock returns (although when implemented in practice, this may be significantly less profitable with all of the fees). We may look at this strategy in more detail in the session where we go through this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Extension activities\n",
    "We will now discuss some extension activities one can do to improve on our above work by:\n",
    "- Improving the performance\n",
    "- Improving the accuracy of our end results\n",
    "- Exploring other models with practical value in other contexts\n",
    "\n",
    "As we will have limited time in the session, and some extensions are open ended and complex, we will focus on a select few for the session. You are free to attempt whichever extensions you wish, but only the first section will be covered in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 - Extensions for the session\n",
    "The following extension activities are entirely optional. If there is enough time in the session, we may go through some or all of them:\n",
    "- Filtering the options based on (some of) the criterion stated just after the last volatility surface plot. (See also: [this page on building reasonable volatility surfaces](https://tsimagine.com/insights/thinking-about-building-a-volatility-surface-think-again/)). This will hopefully make the plots look more reasonable, and reduce the chances of arbitrages occurring in our surfaces.\n",
    "- Faster IV computations - it takes some time to compute IVs, so performance improvements would be worthwhile:\n",
    "    - Experimenting with faster normal CDF computations (for instance, using some of the ideas covered in this paper: [Approximating the cumulative distribution function of the normal distribution](http://jsr.isrt.ac.bd/wp-content/uploads/41n1_5.pdf)).\n",
    "    - Implementing the Hybrid Newton method for root finding discussed just before we implemented the Brent method, which is useful for implied volatilities as we have a closed form expression for the derivative.\n",
    "- Different pricing models:\n",
    "    - One alternative to the Black-Scholes model is the Bachelier model. This model assumes S_t is a normally distributed variable instead of a log-normally distributed one which leads to the possibility of prices being negative! This is generally seen as a downside, since stocks shouldn't have negative values. However, in 2020 oil prices dropped so sharply that for a time they were negative, and at that time some exchanges swapped to the Bachelier implied volatility instead of the Black-Scholes implied volatility. Fortunately, the Bachelier IV can be computed very quickly without an iterative algorithm. A great paper for further reading on the Bachelier model is this: [A Black-Scholes user's guide to the Bachelier model](https://arxiv.org/abs/2104.08686). It should have all the information you need to understand the model and to make a Bachelier volatility surface (as well as much more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 - Bonus extensions\n",
    "There are also some other extensions we think may be interesting to try out in your own time, but would take too much time to properly address in the session. If you do any of these we'd greatly appreciate updates on how they went:\n",
    "- Modelling Volatility surfaces:\n",
    "    - Implementing the SVI model discussed previously. The original SVI model paper is [Arbitrage-free SVI volatility surfaces](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323). There's also a very impressive Masters Thesis that explains the SVI model and some extensions to it: [The SVI implied volatility model and its calibration](https://kth.diva-portal.org/smash/get/diva2:744907/FULLTEXT02.pdf). Links to papers on some extensions (SSVI, eSSVI) can be found in the references. \n",
    "    - Using VAEs to estimate / interpolate over the missing regions of the volatility surface. A company that makes valuation and risk management tools, Riskfuel Analytics, uses (or once used) variational autoencoders to quickly determine volatility surfaces for different assets. More details can be found in this paper: [Variational Autoencoders: A Hands-Off Approach to Volatility](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323)\n",
    "    - Some other approaches try to model the probability density of the time T price of the underlying. A method from this paper: [Option-based Equity Risk Premiums](https://arxiv.org/pdf/1910.14522) suggests the use of Gaussian Mixture Models for the underlying, fitting these models so the resulting density matches the implied volatilities observed. One can then easily compute the rest of the volatility surface using the pdf of the underlying.\n",
    "    - [Kriging the Local Volatility Surface](https://www.bayes.city.ac.uk/__data/assets/pdf_file/0010/640477/SIFIN_Option_Pricing.pdf) describes a Kriging based volatility surface interpolation method. This method allows for no-arbitrage constraints and can be evaluated relatively quickly.\n",
    "    - For interest, this paper has a comparison of many different volatility surface construction methods' performance on a large dataset of options prices: [Implied volatility surfaces: a comprehensive analysis using half a billion option prices](https://link.springer.com/article/10.1007/s11147-023-09195-5)\n",
    "- Even faster IV computations:\n",
    "    - This paper by Peter Jaeckel is slightly outdated, but has a much faster method of computing the implied volatility than ours: [By Implication](http://www.jaeckel.org/ByImplication.pdf)\n",
    "    - This paper has a more modern (and faster) method of computing the implied volatility: [Let's be rational](http://www.jaeckel.org/LetsBeRational.pdf)\n",
    "- Trading strategies:\n",
    "    - Another extension is to implement the volatility term structure trading strategy mentioned above. A paper that implements this can be found here: [Equity Volatility Term Structures and the Cross-Section of Option Returns](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1944298)\n",
    "    - You could also look into a strategy which makes use of the full volatility surface instead of only the volatility term structure for a fixed strike or the volatility skew for a single maturity date. An example is this paper: [Risk-Neutral Skewness and Stock Outperformance](https://wp.lancs.ac.uk/fofi2018/files/2018/03/FoFI-2017-0020-Konstantinos-Gkionis.pdf) which uses Risk-Neutral Skewness, a measure computed from implied volatilities to generate returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Volatility Surfaces in Algorithmic Trading Strategies\n",
    "In the session, we'll go through some possible applications of the volatility surface for trading strategies. One thing to think about is the following strategy:\n",
    "- In many aspects of finance we see mean reversion, particularly over longer periods\n",
    "- We can compute the long term mean volatility based on historical realised volatility\n",
    "- For a given option, we can then compare this to the current implied volatility:\n",
    "    - If the implied volatility is much higher, we sell the option as it's overpriced relative to historical volatility, and we predict the volatility will revert to the mean.\n",
    "    - If the implied volatility is much lower, we buy the option as it's underpriced relative to historical volatility, and we predict the volatility will revert to the mean.\n",
    "\n",
    "How do you think this strategy would perform?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - References:\n",
    "1. General information:\n",
    "    - Cambridge Stochastic Financial Models Lecture Notes - James Norris, 2019. https://www.statslab.cam.ac.uk/~james/Lectures/sfm.pdf\n",
    "    - A review on Implied volatility calculation - Giuseppe Orlando, Giovanni Taglialatela, 2017. https://www.sciencedirect.com/science/article/pii/S0377042717300602\n",
    "    - By Implication - Peter Jaeckel, 2010. http://www.jaeckel.org/ByImplication.pdf\n",
    "2. What is the volatility surface:\n",
    "    - Implied volatility explanation: How Implied Volatility (IV) Works With Options and Examples - Akhilesh Ganti, 2024. https://www.investopedia.com/terms/i/iv.asp\n",
    "    - Volatility surface explanation: The Volatlity Surface explained - Craig Anthony, 2023. https://www.investopedia.com/articles/stock-analysis/081916/volatility-surface-explained.asp\n",
    "    - Historical Volatility Calculation - https://www.investopedia.com/articles/stock-analysis/081916/volatility-surface-explained.asp\n",
    "3. Getting options chains data:\n",
    "    - Getting options with yfinance - 2023. https://www.fintut.com/yahoo-finance-options-python/ \n",
    "4. Computing the implied volatility:\n",
    "    - Algebraic approximations of implied volatility: A new formula for computing implied volatility - Steven Li, 2005. https://www.fintut.com/yahoo-finance-options-python/\n",
    "    - Bisection method (with code): Python Numerical Methods Chapter 19 Section 3 - Bisection Method - Qingkai Kong, Timmy Siauw, Alexandre Bayen, 2020. https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter19.03-Bisection-Method.html\n",
    "    - Newton-Raphson method (with code): Python Numerical Methods Chapter 19 Secton 4 - Newton-Raphson Method - Qingkai Kong, Timmy Siauw, Alexandre Bayen, 2020. https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter19.04-Newton-Raphson-Method.html\n",
    "    - Hybrid Newton-Bisection method: Numerical Recipes in C Section 9.4 (page 362) - William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery, 2002. https://www.grad.hr/nastava/gs/prg/NumericalRecipesinC.pdf\n",
    "    - Brent's method: An algorithm with guaranteed convergence for finding a zero of a function - R. P. Brent, 1971. https://maths-people.anu.edu.au/~brent/pd/rpb005.pdf\n",
    "    - Secant method - BYJU'S. https://byjus.com/maths/secant-method/\n",
    "    - Inverse quadratic interpolation - In a nutshell: Inverse quadratic interpolation - Douglas Wilhelm Harder, 2023. https://ece.uwaterloo.ca/~dwharder/nm/Lecture_materials/pdfs/6.2.6%20Inverse%20quadratic%20interpolation%20in%20a%20nutshell.pdf\n",
    "    - Plotly 3D scatter plot documentation - https://plotly.com/python/3d-scatter-plots/\n",
    "5. Interpolating and Plotting the volatility surface:\n",
    "    - Calendar arbitrage example question - Gordon, 2016. https://quant.stackexchange.com/questions/15215/how-to-exploit-calendar-arbitrage\n",
    "    - The SVI model - Arbitrage Free SVI Volatility Surfaces - Jim Gatheral, Antoine (Jack) Jacquier, 2013. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323\n",
    "    - Arbitrage in SVI model - Arbitrage Free Implied Volatility Surfaces - Michael Roper, 2010. https://talus.maths.usyd.edu.au/u/pubs/publist/preprints/2010/roper-9.pdf\n",
    "    - Bilinear interpolation - https://en.wikipedia.org/wiki/Bilinear_interpolation\n",
    "    - Visualising Delaunay Triangulation - Ian Henry, 2022. https://ianthehenry.com/posts/delaunay/\n",
    "    - Linear interpolation with Barycentric coordinates: Barycentric interpolation: fast interpolation on arbitrary grids - Simon Barthelme, 2013. https://dahtah.wordpress.com/2013/03/06/barycentric-interpolation-fast-interpolation-on-arbitrary-grids/\n",
    "    - Plotly 3D surface plot documentation - https://plotly.com/python/3d-scatter-plots/\n",
    "    - CloughTocher2DInterpolator - SciPy documentation, https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.CloughTocher2DInterpolator.html\n",
    "    - Considerations for building a volatility surface: Thinking About Building a Volatility Surface? Think Again. - TS Imagine team, https://tsimagine.com/insights/thinking-about-building-a-volatility-surface-think-again/\n",
    "6. Volatility surface terms and properties:\n",
    "    - Volatility Skew: How it Can Signal Market Sentiment - Will Kenton, 2023. https://www.investopedia.com/terms/v/volatility-skew.asp\n",
    "    - What Is a Volatility Smile and What Does It Tell Options Traders? - Cory Mitchell, 2021. https://www.investopedia.com/terms/v/volatilitysmile.asp\n",
    "    - Link between a risky future event and inverted volatility smiles: Pricing Event Risk: Evidence from Concave\n",
    "Implied Volatility Curves - Lykourgos Alexiou, Amit Goyal, Alexandros Kostakis, Leonidas Rompolis, 2021. https://www.efmaefm.org/0EFMAMEETINGS/EFMA%20ANNUAL%20MEETINGS/2022-Rome/papers/EFMA%202022_stage-3032_question-Full%20Paper_id-108.pdf\n",
    "    - Term structure of Implied Volatility - Martin Noel, 2017. https://www.optionmatters.ca/term-structure-implied-volatility/\n",
    "    - Relationship between volatility term structure slope and returns: Aurelio Vasquez, 2011. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1944298\n",
    "7. Extensions:\n",
    "    - Considerations for building a volatility surface: Thinking About Building a Volatility Surface? Think Again. - TS Imagine team, https://tsimagine.com/insights/thinking-about-building-a-volatility-surface-think-again/\n",
    "    - Approximting the Cumulative Distribution Function of the Normal Distribution - Amit Choudhury, Subhasis Ray, Pradipta Sarkar, 2007. http://jsr.isrt.ac.bd/wp-content/uploads/41n1_5.pdf\n",
    "    - A Black-Scholes user's guide to the Bachelier model - Jaehyuk Choi, Minsuk Kwak, Chyng Wen Tee, Yumeng Wang, 2021. https://arxiv.org/abs/2104.08686\n",
    "    - The SVI model - Arbitrage Free SVI Volatility Surfaces - Jim Gatheral, Antoine (Jack) Jacquier, 2013. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323. Presentation version: https://mfe.baruch.cuny.edu/wp-content/uploads/2013/01/OsakaSVI2012.pdf\n",
    "    - Thesis on fitting the SVI model: The SVI implied volatility model and its calibration - Alexander Aurell, 2014. https://kth.diva-portal.org/smash/get/diva2:744907/FULLTEXT02.pdf\n",
    "    - A follow up to the SVI introducing an arbitrage free version, the Surface SVI (SSVI): Arbitrage-Free SVI Volatility Surfaces - Jim Gatheral, Antoine (Jack) Jacquier, 2014. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2033323\n",
    "    - An advancement on the SSVI paper: The Extended SSVI Volatility surface - Sebas Hendriks, Claude Martini, 2017. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2971502 \n",
    "    - VAEs for volatility surfaces: Variational Autoencoders: A Hands-Off Approach to Volatility - Maxime Bergeron, Nicholas Fung, John Hull, Zissis Poulos, 2021. https://arxiv.org/abs/2102.03945\n",
    "    - GMMs for volatility surface modelling: Option-based Equity Risk Premiums - Alan Lewis, 2020. https://arxiv.org/abs/1910.14522\n",
    "    - (Slides on) Kriging the Local Volatility Surface - Matthew Dixon, 2021. https://www.bayes.city.ac.uk/__data/assets/pdf_file/0010/640477/SIFIN_Option_Pricing.pdf\n",
    "    - Comparing volatility surface models: Implied volatility surfaces: a comprehensive analysis using half a billion option prices - Maxim Ulrich, Lukas Zimmer, Constantin Merbecks, 2023. https://link.springer.com/article/10.1007/s11147-023-09195-5\n",
    "    - A fast approach to implied volatility computations: By Implication - Peter Jaeckel, 2010. http://www.jaeckel.org/ByImplication.pdf\n",
    "    - An even more modern approach: Let's be rational - Peter Jaeckel, 2016. http://www.jaeckel.org/LetsBeRational.pdf\n",
    "    - Equity Volatility Term Structures and the Cross-Section of Option Returns - Aurelio Vasquez, 2015. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1944298\n",
    "    - Risk-Neutral Skewness and Stock Outperformance, Konstantinos Gkionis, Alexandros Kostakis, George Skiadopoulos, Przemyslaw S. Stilger, 2017. https://wp.lancs.ac.uk/fofi2018/files/2018/03/FoFI-2017-0020-Konstantinos-Gkionis.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Exercise hints:\n",
    "Don't scroll any further unless you want to see the spoilers.\n",
    "\n",
    "Exericse 1 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Consider the first fundamental theorem of calculus.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 1 - Hint 2: \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "If the derivative exists, a function is continuous. If it is positive, a function is increasing\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 2 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Look at the RHS of the equation for Put-Call parity. Is it a function of $\\sigma$?\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 3 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<pre>for expiry in expiry_dates:\n",
    "\n",
    "    current_option_chain = yf_ticker.option_chain(expiry)\n",
    "\n",
    "    ...\n",
    "</pre>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 4 - Hint 1: \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "If $K = S_t e^{r(T-t)}$, then what is $ln(S_t/K)$? \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 6 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<pre>while counter <= max_iterations and abs(FUN(midpoint)-target_value) > tol:\n",
    "\n",
    "    # Check which half of the interval the root is in\n",
    "    if (FUN(init_lower)-target_value)* (FUN(midpoint)-target_value)<0:\n",
    "\n",
    "    ...\n",
    "</pre>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 9 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "A general method for these sorts of problems is to buy the option which seems too cheap and sell the one which seems too expensive. Hence, start with selling the $T_1$ option and buying the $T_2$ option. \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 9 - Hint 2:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "If At time $T_1$, if $S_{T_1} > K_2$ consider buying / selling n shares of the underlying.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 10a - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Verify that $(x,0)$ and $(0,y)$ are not arbitrages. Note that for $\\lambda > 0$, $(\\lambda x, \\lambda y)$ is an arbitrage if and only if $(x,y)$ is. Without loss of generality pick $\\lambda$ such that $|y| = 1$. \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 10a - Hint 2:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Consider different cases for different values of $S_T$. In particular what happens as $S_T \\to \\infty$?\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 12 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Try commenting our different parts to determine which section of code contains the bug.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Exercise 13 - Hint 1:\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Let $\\epsilon$ be the smallest positive value you can represent with a standard float in python. What is $\\epsilon$?\n",
    "\n",
    "What does your computer say $(1-\\epsilon)$ is?\n",
    "\n",
    "<br/><br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
